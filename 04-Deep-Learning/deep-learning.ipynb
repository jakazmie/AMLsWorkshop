{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7 - Transfer Learning\n",
    "\n",
    "In this lab, you will developed a custom image classification model to automatically classify the type of land shown in aerial images of 224-meter x 224-meter plots. Land use classification models can be used to track urbanization, deforestation, loss of wetlands, and other major environmental trends using periodically collected aerial imagery. The images used in this lab are based off of imagery from the U.S. National Land Cover Database. U.S. National Land Cover Database defines six primary classes of land use: *Developed*, *Barren*, *Forested*, *Grassland*, *Shrub*, *Cultivated*. Example images from each land use class are shown here:\n",
    "\n",
    "Developed | Cultivated | Barren\n",
    "--------- | ------ | ----------\n",
    "![Developed](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/developed1.png) | ![Cultivated](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/cultivated1.png) | ![Barren](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/barren1.png)\n",
    "\n",
    "Forested | Grassland | Shrub\n",
    "---------| ----------| -----\n",
    "![Forested](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/forest1.png) | ![Grassland](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/grassland1.png) | ![Shrub](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/shrub1.png)\n",
    "\n",
    "You shall employ a machine learning technique called transfer learning. Transfer learning is one of the fastest (code and run-time-wise) ways to start using deep learning. It allows for the reuse of knowledge gained while solving one problem to a different but related problem. For example, knowledge gained while learning to recognize landmarks and landscapes could apply when trying to recognize aerial land plots. Transfer Learning makes it feasible to train very effective ML models on relatively small training data sets.\n",
    "\n",
    "Although the primary goal of this lab is to understand how to use Azure ML to orchestrate deep learning workflows rather then to dive into Deep Learning techniques, ask the instructor if you want to better understand the approach utilized in the lab.\n",
    "\n",
    "You will start by pre-processing training images into a set of powerful features - sometimes referred to as bottleneck features.\n",
    "\n",
    "To create bottleneck features you will utilize a pre-trained Deep Learning network that was trained on a general computer vision domain. \n",
    "\n",
    "Although, the pre-trained network does not know how to classify aerial land plot images, it knows enough about representing image concepts that if we use it to pre-process aerial images, the extracted image features can be used to effectively train a relatively simple classifier on a **limited number** of samples.\n",
    "\n",
    "The below diagram represents the architecture of our solution.\n",
    "\n",
    "![Transfer Learning](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/tlcl.png)\n",
    "\n",
    "We will use **ResNet50** trained on **imagenet** dataset to extract features. We will occasionally refer to this component of the solution as a featurizer. The output of the featurizer is a vector of 2048 floating point numbers, each representing a feature extracted from an image. \n",
    "\n",
    "We will then use extracted features to train a simple fully connected neural network (the top) that will peform final image classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AML Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /data/home/demouser/notebooks/AMLsLabs/01-aml-walkthrough/aml_config/config.json\n",
      "jkamlslab\n",
      "jkamlslab\n",
      "eastus2\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'aerial-feature-engineering'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "The Python script processes an input image dataset into an output bottleneck feature set. The script expects the images to be organized in the below folder structure:\n",
    "```\n",
    "Barren/\n",
    "Cultivated/\n",
    "Developed/\n",
    "Forest/\n",
    "Herbaceous/\n",
    "Shrub/\n",
    "```\n",
    "\n",
    "The location of the input dataset and the location where to save the output dataset are passed to the script as command line parameters. The output dataset will be stored in a binary HDF5 data format used commonly in Machine Learning and High Performance Computing solutions.\n",
    "\n",
    "The script is designed to work with a large number of images. As such it does not load all input images to memory at once. Instead it utilizes a utility function `load_images` to feed the featurizer. The function yields batches of images - as Numpy arrays - preprocessed to the format required by **ResNet50**. \n",
    "\n",
    "We will not attempt to run the script on a full dataset in a local environment. It is very computationally intensive and unless you run it in an evironment equipped with a powerful GPU it would be very slow. \n",
    "\n",
    "However, we will demonstrate how to run the script locally using the same small development dataset we used in the previous lab. Running the script locally under the control of Azure ML can be very usefull during development and debugging.\n",
    "\n",
    "To process the full dataset we will execute the script on a remote Azure ML Compute equipped with NVidia GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a feature engineering script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./script/extract.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/extract.py\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import azureml.contrib.brainwave.models.utils as utils\n",
    "from azureml.contrib.brainwave.models import QuantizedResnet50\n",
    "\n",
    "\n",
    "def get_batch(pathnames, batchsize=64):\n",
    "    \"\"\"Yield succesive batches of images\"\"\"\n",
    "    for i in range(0, len(pathnames), batchsize):\n",
    "        yield pathnames[i:i+batchsize]\n",
    "        \n",
    "\n",
    "def load_images(batch):\n",
    "    \"\"\"Return a batch of images as a list of bytes sequences\"\"\"\n",
    "    images = []\n",
    "    for path in batch:\n",
    "        with open(path, 'rb') as f:\n",
    "            images.append(f.read())\n",
    "    return images\n",
    "\n",
    "def create_bottleneck_features():\n",
    "    \"\"\"Createl bottleneck features and save them to H5 formatted file\"\"\"\n",
    "    img_dir = FLAGS.input_data_dir\n",
    "    \n",
    "    # Label images \n",
    "    \n",
    "    # Create the dictionary that maps class names into numeric labels   \n",
    "    label_map = {\n",
    "        \"Barren\": 0,\n",
    "        \"Cultivated\": 1,\n",
    "        \"Developed\": 2,\n",
    "        \"Forest\": 3,\n",
    "        \"Herbaceous\": 4,\n",
    "        \"Shrub\": 5}    \n",
    "\n",
    "    # Create a list of all images in a root folder with associated numeric labels\n",
    "    folders = list(label_map.keys())\n",
    "    labeled_image_list = [(os.path.join(img_dir, folder, image), label_map[folder]) \n",
    "                          for folder in folders \n",
    "                          for image in os.listdir(os.path.join(img_dir, folder))\n",
    "                              ]\n",
    "    # Shuffle the list\n",
    "    random.shuffle(labeled_image_list)\n",
    "    image_paths, labels = zip(*labeled_image_list)\n",
    "    \n",
    "    # Build featurizer graph\n",
    "    \n",
    "    # Convert input images (loaded as bytes sequences) into (224, 224, 3) tensors\n",
    "    # with pixel values in Caffe encoding\n",
    "    in_images = tf.placeholder(tf.string)\n",
    "    image_tensors = utils.preprocess_array(in_images)\n",
    "\n",
    "    # Create ResNet152 \n",
    "    model_path = os.path.expanduser('~/models')\n",
    "    resnet = QuantizedResnet50(model_path, is_frozen=True)\n",
    "\n",
    "    # Import ResNet152 graph\n",
    "    features = resnet.import_graph_def(input_tensor=image_tensors)\n",
    "    \n",
    "    # Generate bottleneck features\n",
    "    print(\"Generating bottleneck features\")\n",
    "    bottleneck_features = []\n",
    "    with tf.Session() as sess:\n",
    "        for paths in tqdm(get_batch(image_paths)):\n",
    "            image_batch = load_images(paths)\n",
    "            result = sess.run([features], feed_dict={in_images: image_batch})\n",
    "            result = np.reshape(result[0], (len(result[0]), 2048))\n",
    "            bottleneck_features.extend(result)\n",
    "        \n",
    "    bottleneck_features = np.array(bottleneck_features)\n",
    "    print(bottleneck_features.shape)\n",
    "        \n",
    "    # Save the bottleneck features to HDF5 file\n",
    "    filename = FLAGS.file_name\n",
    "    output_file = os.path.join(FLAGS.output_data_dir, filename)\n",
    "    labels = np.asarray(labels)\n",
    "    print(\"Saving bottleneck features to {}\".format(output_file))\n",
    "    print(\"   Features: \", bottleneck_features.shape)\n",
    "    print(\"   Labels: \", labels.shape)\n",
    "    with h5py.File(output_file, \"w\") as hfile:\n",
    "        features_dset = hfile.create_dataset('features', data=bottleneck_features)\n",
    "        labels_dset = hfile.create_dataset('labels', data=labels)\n",
    "    \n",
    "    print(\"Done\")\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Default global parameters\n",
    "tf.app.flags.DEFINE_integer('batch_size', 64, \"Number of images per batch\")\n",
    "tf.app.flags.DEFINE_string('input_data_dir', 'aerialtiny', \"Folder with training and validation images\")\n",
    "tf.app.flags.DEFINE_string('output_data_dir', 'bottleneck_features', \"A folder for saving bottleneck features\")\n",
    "tf.app.flags.DEFINE_string('file_name', 'aerial_bottleneck_resnet50.h5', \"Name of output training file\")\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    print(\"Starting\")\n",
    "    print(\"Reading images from:\", FLAGS.input_data_dir)\n",
    "    print(\"The output bottleneck file will be saved to:\", FLAGS.output_data_dir)\n",
    "\n",
    "    os.makedirs(FLAGS.output_data_dir, exist_ok=True)\n",
    "\n",
    "    create_bottleneck_features()\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Azure ML Managed Compute\n",
    "\n",
    "We will use an autoscale cluster of *Standard_NC6* VMs (equipped with Tesla K80 GPU). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found compute target. just use it. gpucluster\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "\n",
    "# choose a name for your cluster\n",
    "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"gpucluster\")\n",
    "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 1)\n",
    "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\n",
    "\n",
    "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_NC6\")\n",
    "\n",
    "if compute_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[compute_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('found compute target. just use it. ' + compute_name)\n",
    "else:\n",
    "    print('creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\n",
    "                                                                min_nodes = compute_min_nodes, \n",
    "                                                                max_nodes = compute_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\n",
    "\n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "\n",
    "     # For a more detailed view of current AmlCompute status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Datastores \n",
    "The training images have been uploaded to a public Azure blob storage container. We will register this container as an AML Datastore within our workspace. Before the data prep script runs, the datastore's content - training images - will be copied to the local storage on the compute nodes.\n",
    "\n",
    "After the script completes, its output - the bottleneck features file - will be uploaded by AML to the workspace's default datastore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing datastore for input images: input_images\n",
      "input_images AzureBlob azureailabs aerial-med\n",
      "Using the default datastore for output: \n",
      "workspaceblobstore AzureBlob jkamlslastoragevfzvtchj azureml-blobstore-b9d096b6-8b2a-49bb-aef5-cc1bd0f6b751\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "images_account = 'azureailabs'\n",
    "images_container = 'aerial-small'\n",
    "datastore_name = 'input_images'\n",
    "\n",
    "# Check if the datastore exists. If not create a new one\n",
    "try:\n",
    "    input_ds = Datastore.get(ws, datastore_name)\n",
    "    print('Found existing datastore for input images:', input_ds.name)\n",
    "except:\n",
    "    input_ds = Datastore.register_azure_blob_container(workspace=ws, datastore_name=datastore_name,\n",
    "                                            container_name=images_container,\n",
    "                                            account_name=images_account)\n",
    "    print('Creating new datastore for input images')\n",
    "\n",
    " \n",
    "   \n",
    "print(input_ds.name, input_ds.datastore_type, input_ds.account_name, input_ds.container_name)\n",
    "\n",
    "output_ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for output: \")\n",
    "print(output_ds.name, output_ds.datastore_type, output_ds.account_name, output_ds.container_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AML Experiment\n",
    "We will track runs of the feature engineering script in a dedicated Experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment\n",
    "experiment_name = 'aerial-feature-engineering'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start and monitor a remote run\n",
    "\n",
    "We will run a script on a single node in a docker container. The docker image will be configured and created using AML APIs.\n",
    "\n",
    "The first run takes longer. The subsequent runs, as long as the script dependencies don't change, are much faster.\n",
    "\n",
    "You can check the progress of a running job in multiple ways: Azure Portal, AML Jupyter Widgets, log files streaming. We will use AML Jupyter Widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "# Define the location of the dataprep script and the location for the output bottleneck files\n",
    "script_folder = 'script'\n",
    "script_name = 'extract.py'\n",
    "output_dir = 'bottleneck_features'\n",
    "pip_packages = ['h5py', 'pillow', 'tqdm', 'azureml-sdk[contrib]', 'tensorflow-gpu==1.10']\n",
    "\n",
    "script_params = {\n",
    "    '--input_data_dir': input_ds.as_download(),\n",
    "    '--output_data_dir': output_dir,\n",
    "    '--file_name': 'aerial_bottleneck_resnet50_brainwave.h5'\n",
    "}\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=compute_target,\n",
    "                entry_script=script_name,\n",
    "                node_count=1,\n",
    "                process_count_per_node=1,\n",
    "                use_gpu=True,\n",
    "                pip_packages=pip_packages,\n",
    "                inputs=[output_ds.path(output_dir).as_upload(path_on_compute=output_dir)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the run and start RunDetails widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575e8b66033648f79836c1896f46909c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'NOTSET',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "\n",
    "tags = {\"Compute target\": \"AML Compute GPU\", \"DNN\": \"Brainwave ResNet50\"}\n",
    "run = exp.submit(config=est, tags=tags)\n",
    "\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block to wait till the run finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: aerial-feature-engineering_1544072574230\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "\n",
      "Logging into Docker registry: jkamlslaacrizqtrwph.azurecr.io\n",
      "Login Succeeded\n",
      "Docker login(s) took 5.330162286758423 seconds\n",
      "Building image with name jkamlslaacrizqtrwph.azurecr.io/azureml/azureml_e91631b22e17e89880cec955207fb48b\n",
      "Sending build context to Docker daemon  139.8kB\n",
      "\n",
      "Step 1/13 : FROM mcr.microsoft.com/azureml/base-gpu:0.2.0\n",
      "0.2.0: Pulling from azureml/base-gpu\n",
      "3b37166ec614: Already exists\n",
      "504facff238f: Already exists\n",
      "ebbcacd28e10: Already exists\n",
      "c7fb3351ecad: Already exists\n",
      "2e3debadcbf7: Already exists\n",
      "7ff5eaad8a49: Pulling fs layer\n",
      "8697dd9e92dc: Pulling fs layer\n",
      "112403772eb3: Pulling fs layer\n",
      "0431a9485aa5: Pulling fs layer\n",
      "a8ab5d81aeba: Pulling fs layer\n",
      "d09075b02960: Pulling fs layer\n",
      "0431a9485aa5: Waiting\n",
      "a8ab5d81aeba: Waiting\n",
      "d09075b02960: Waiting\n",
      "7ff5eaad8a49: Verifying Checksum\n",
      "7ff5eaad8a49: Download complete\n",
      "7ff5eaad8a49: Pull complete\n",
      "8697dd9e92dc: Verifying Checksum\n",
      "8697dd9e92dc: Download complete\n",
      "0431a9485aa5: Verifying Checksum\n",
      "0431a9485aa5: Download complete\n",
      "a8ab5d81aeba: Verifying Checksum\n",
      "a8ab5d81aeba: Download complete\n",
      "112403772eb3: Verifying Checksum\n",
      "112403772eb3: Download complete\n",
      "8697dd9e92dc: Pull complete\n",
      "d09075b02960: Verifying Checksum\n",
      "d09075b02960: Download complete\n",
      "112403772eb3: Pull complete\n",
      "0431a9485aa5: Pull complete\n",
      "a8ab5d81aeba: Pull complete\n",
      "d09075b02960: Pull complete\n",
      "Digest: sha256:a1e3270558b0c6158952bc60406694743fa3a3aaa373d88a31625be2e625639b\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/base-gpu:0.2.0\n",
      " ---> 948446f23e82\n",
      "Step 2/13 : USER root\n",
      " ---> Running in 050ca50879c3\n",
      " ---> b9aa16dec9ec\n",
      "Removing intermediate container 050ca50879c3\n",
      "Step 3/13 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in bc486ba623db\n",
      " ---> 0f82961536e8\n",
      "Removing intermediate container bc486ba623db\n",
      "Step 4/13 : WORKDIR /\n",
      " ---> 2cd5ad3e211a\n",
      "Removing intermediate container 38cca9b8a2d6\n",
      "Step 5/13 : COPY azureml-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> 123aaeb62867\n",
      "Step 6/13 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.0; then conda install conda==4.4.11; fi\n",
      " ---> Running in e86a39b5ac60\n",
      " ---> 823d9a829575\n",
      "Removing intermediate container e86a39b5ac60\n",
      "Step 7/13 : COPY azureml-setup/mutated_conda_dependencies.yml azureml-setup/mutated_conda_dependencies.yml\n",
      " ---> af128969104f\n",
      "Step 8/13 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_c77fd37935750ffd1124c72fa1618fa3 -f azureml-setup/mutated_conda_dependencies.yml && ldconfig\n",
      " ---> Running in bbacc62f6d24\n",
      "Solving environment: ...working... done\n",
      "\u001b[91m\n",
      "ncurses-6.0          | 920 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | #######9   |  79% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | ########9  |  89% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | #########8 |  99% \u001b[0m\u001b[91m\n",
      "ncurses-6.0          | 920 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | #######7   |  77% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | #########8 |  99% \u001b[0m\u001b[91m\n",
      "libstdcxx-ng-8.2.0   | 2.9 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "setuptools-40.6.2    | 604 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "setuptools-40.6.2    | 604 KB    | ########4  |  84% \u001b[0m\u001b[91m\n",
      "setuptools-40.6.2    | 604 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########   |  80% \u001b[0m\u001b[91m\n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "certifi-2018.10.15   | 139 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "certifi-2018.10.15   | 139 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "xz-5.2.4             | 366 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "xz-5.2.4             | 366 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "tk-8.6.8             | 3.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #######6   |  77% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########7  |  87% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | #########6 |  96% \u001b[0m\u001b[91m\n",
      "tk-8.6.8             | 3.1 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "openssl-1.0.2p       | 3.5 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2p       | 3.5 MB    | #######5   |  76% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2p       | 3.5 MB    | ########9  |  89% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2p       | 3.5 MB    | #########8 |  99% \u001b[0m\u001b[91m\n",
      "openssl-1.0.2p       | 3.5 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ##1        |  21% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ####7      |  48% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #######5   |  75% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | #########1 |  92% \u001b[0m\u001b[91m\n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "libedit-3.1          | 171 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "pip-18.1             | 1.8 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "pip-18.1             | 1.8 MB    | #######8   |  78% \u001b[0m\u001b[91m\n",
      "pip-18.1             | 1.8 MB    | #########  |  91% \u001b[0m\u001b[91m\n",
      "pip-18.1             | 1.8 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "ca-certificates-2018 | 124 KB    |            |   0% \u001b[0m\u001b[91m\n",
      "ca-certificates-2018 | 124 KB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "wheel-0.32.3         | 35 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "wheel-0.32.3         | 35 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libffi-3.2.1         | 43 KB     |            |   0% \u001b[0m\u001b[91m\n",
      "libffi-3.2.1         | 43 KB     | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "libgcc-ng-8.2.0      | 7.6 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | #######2   |  73% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | #########4 |  95% \u001b[0m\u001b[91m\n",
      "libgcc-ng-8.2.0      | 7.6 MB    | ########## | 100% \u001b[0m\u001b[91m\n",
      "\n",
      "readline-7.0         | 1.1 MB    |            |   0% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 1.1 MB    | ########1  |  81% \u001b[0m\u001b[91m\n",
      "readline-7.0         | 1.1 MB    | ########## | 100% \u001b[0m\n",
      "Downloading and Extracting Packages\n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Collecting azureml-defaults (from -r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/4e/27a93da1484f06043f0a6b4d4f3e5ed7212c513eb0d2021cb434c4b2a29d/azureml_defaults-1.0.2-py2.py3-none-any.whl\n",
      "Collecting h5py (from -r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/8e/cb/726134109e7bd71d98d1fcc717ffe051767aac42ede0e7326fd1787e5d64/h5py-2.8.0-cp36-cp36m-manylinux1_x86_64.whl (2.8MB)\n",
      "Collecting pillow (from -r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 3))\n",
      "  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "Collecting tqdm (from -r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/91/55/8cb23a97301b177e9c8e3226dba45bb454411de2cbd25746763267f226c2/tqdm-4.28.1-py2.py3-none-any.whl (45kB)\n",
      "Collecting azureml-sdk[contrib] (from -r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/ec/b247beb617cd9006a21893470db40db4a0d01d71e743b8f5a516bec1ba63/azureml_sdk-1.0.2-py3-none-any.whl\n",
      "Collecting tensorflow-gpu==1.10 (from -r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/64/ca/830b7cedb073ae264d215d51bd18d7cff7a2a47e39d79f6fa23edae17bb2/tensorflow_gpu-1.10.0-cp36-cp36m-manylinux1_x86_64.whl (253.2MB)\n",
      "Collecting azureml-core==1.0.2.* (from azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/ce/3443d87ba4735de037003413063b7d5d77b00543b787c495b0ab682be254/azureml_core-1.0.2-py2.py3-none-any.whl (651kB)\n",
      "Collecting applicationinsights>=0.11.0 (from azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/c8/7848a0dd85158930b859eb8be1e38fc76a91f0a040d491723ebb356d7358/applicationinsights-0.11.7-py2.py3-none-any.whl (56kB)\n",
      "Collecting six (from h5py->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n",
      "Collecting numpy>=1.7 (from h5py->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/7f/9d804d2348471c67a7d8b5f84f9bc59fd1cefa148986f2b74552f8573555/numpy-1.15.4-cp36-cp36m-manylinux1_x86_64.whl (13.9MB)\n",
      "Collecting azureml-pipeline==1.0.2.* (from azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/6f/3c6ee3c6d4fc0f1f6871ac634565aa178a170725f9c93429922e78db7b40/azureml_pipeline-1.0.2-py3-none-any.whl\n",
      "Collecting azureml-train==1.0.2.* (from azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/82/97/039c725b1c58ca41735277b966b60f7109a3caf9d2c4d94879b66fe4ff03/azureml_train-1.0.2-py3-none-any.whl\n",
      "Collecting azureml-contrib-tensorboard==1.0.2.*; extra == \"contrib\" (from azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/e1/234226c279edd1e900c58af3b34e3d80b4d6a8eafc3bb9b7076b7c9b89c1/azureml_contrib_tensorboard-1.0.2-py3-none-any.whl\n",
      "Collecting azureml-contrib-server==1.0.2.*; extra == \"contrib\" (from azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/83/fe/1338c50c34dfed02c01d1e3b56a58f94056a02925e727a9998ba20cf0541/azureml_contrib_server-1.0.2-py3-none-any.whl\n",
      "Collecting azureml-contrib-brainwave==1.0.2.*; extra == \"contrib\" (from azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/0b/37/b87284e1867f285dac11492b0fc245510d0b7ef7333768a165a703b855e3/azureml_contrib_brainwave-1.0.2-py3-none-any.whl (50kB)\n",
      "Collecting azureml-contrib-services==1.0.2.*; extra == \"contrib\" (from azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/d6/aa1567856516f2c74f7e3295f83c61cb2b8153a929da7d51c7440cb7829e/azureml_contrib_services-1.0.2-py3-none-any.whl\n",
      "Collecting azureml-contrib-run==1.0.2.*; extra == \"contrib\" (from azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/fe/f3/7c4e6c6d938fd47cd7acd930c1e97fc0bfdb456715dc76514074ef3aa909/azureml_contrib_run-1.0.2-py2.py3-none-any.whl\n",
      "Requirement already satisfied: wheel>=0.26 in /azureml-envs/azureml_c77fd37935750ffd1124c72fa1618fa3/lib/python3.6/site-packages (from tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6)) (0.32.3)\n",
      "Collecting setuptools<=39.1.0 (from tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/10/79282747f9169f21c053c562a0baa21815a8c7879be97abd930dbcf862e8/setuptools-39.1.0-py2.py3-none-any.whl (566kB)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting protobuf>=3.6.0 (from tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/f9/28787754923612ca9bfdffc588daa05580ed70698add063a5629d1a4209d/protobuf-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "Collecting tensorboard<1.11.0,>=1.10.0 (from tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/17/ecd918a004f297955c30b4fffbea100b1606c225dbf0443264012773c3ff/tensorboard-1.10.0-py3-none-any.whl (3.3MB)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/97/64/2975e1d234c7bccf7a63e84452800f96aeecfd87d8310f77aa4afcda6bed/grpcio-1.17.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/0c/63/f505d2d4c21db849cf80bad517f0065a30be6b006b0a5637f1b95584a305/absl-py-0.6.1.tar.gz (94kB)\n",
      "Collecting astor>=0.6.0 (from tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting gast>=0.2.0 (from tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\n",
      "Collecting azure-common>=1.1.12 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ac/d3/055ce7ad06459a415ff9ca210e04c6cbb51bd6564815b7c8ac34bf5a1c39/azure_common-1.1.16-py2.py3-none-any.whl\n",
      "Collecting msrestazure>=0.4.33 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/62/6e/c41d6e2db39f4c6b819cea5b47c36c0fa0e7a931cd39b4c5f19713d28fd1/msrestazure-0.5.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-keyvault>=0.40.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/49/de/0d69aedae7c5f6428314640b65947203ab80409c12b5d4e66fb5b7a4182e/azure_mgmt_keyvault-1.1.0-py2.py3-none-any.whl (111kB)\n",
      "Collecting jsonpickle (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ca/ce/97404d5aeb58e6155c216825c81b50f6eca8a5345c582317ae48391878f8/jsonpickle-1.0-py2.py3-none-any.whl\n",
      "Collecting azure-storage-blob>=1.1.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f7/b7/9b20c39bf411e896d110d01f2551e6e7b397fde6eb06b07293fe29705d13/azure_storage_blob-1.4.0-py2.py3-none-any.whl (75kB)\n",
      "Collecting pathspec (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/84/2a/bfee636b1e2f7d6e30dd74f49201ccfa5c3cf322d44929ecc6c137c486c5/pathspec-0.5.9.tar.gz\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/35/d1/e8887811e8e5ab336e77db7cfb9f451bdae69a8ed97f53cc2cd11fdcac8f/azure_mgmt_containerregistry-2.4.0-py2.py3-none-any.whl (482kB)\n",
      "Collecting azure-cli-core>=2.0.38 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/f0/507c83334d7ee7d588fdd1210b6f470446077c62f3e22fdb955f9d3396f8/azure_cli_core-2.0.52-py2.py3-none-any.whl (106kB)\n",
      "Collecting azure-mgmt-resource>=1.2.1 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/2b/26/c0cb69dfac2e5b7125db034045b8bcf937cf1e8d3df2009a87c33d0959f5/azure_mgmt_resource-2.0.0-py2.py3-none-any.whl (698kB)\n",
      "Collecting backports.tempfile (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b4/5c/077f910632476281428fe254807952eb47ca78e720d059a46178c541e669/backports.tempfile-1.0-py2.py3-none-any.whl\n",
      "Collecting requests>=2.19.1 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ff/17/5cbb026005115301a8fb2f9b0e3e8d32313142fe8b617070e7baad20554f/requests-2.20.1-py2.py3-none-any.whl (57kB)\n",
      "Collecting azure-storage-nspkg>=3.0.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/f6/054ace7b01c6c21b3b95a83c3997f7d6539d939a2c08c4f27f779128a030/azure_storage_nspkg-3.1.0-py2.py3-none-any.whl\n",
      "Collecting SecretStorage<3.0.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a5/a5/0830cfe34a4cfd0d1c3c8b614ede1edb2aaf999091ac8548dd19cb352e79/SecretStorage-2.3.1.tar.gz\n",
      "Collecting urllib3<1.24,>=1.23 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bd/c9/6fdd990019071a4a32a5e7cb78a1d92c53851ef4f56f62a3486e6a7d8ffb/urllib3-1.23-py2.py3-none-any.whl (133kB)\n",
      "Collecting PyJWT (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/02/9b/16c92330f1fb76e3f6372ba6f804d412ec894ee1d9ea31516269b5f6add4/PyJWT-1.7.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-storage>=1.5.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/d9/496b29857a252bc3fcc4bbda069c0eb64b537c8e8f7e342abb4053ba920f/azure_mgmt_storage-3.1.0-py2.py3-none-any.whl (696kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.* (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/60/c7/99b33c53cf3f20a97a4c4bfd3ab66dcc93d99da0a97cc9597aa36ae6bb62/cryptography-2.4.2-cp34-abi3-manylinux1_x86_64.whl (2.1MB)\n",
      "Collecting contextlib2 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a2/71/8273a7eeed0aff6a854237ab5453bc9aa67deb49df4832801c21f0ff3782/contextlib2-0.5.5-py2.py3-none-any.whl\n",
      "Collecting azure-storage-common>=1.1.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/73/84/025ac436a6a1d5516d1a67887d7122b3b2ea04ba6b2d2c46fe949accb62b/azure_storage_common-1.4.0-py2.py3-none-any.whl (46kB)\n",
      "Collecting azure-cli-profile>=2.0.26 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c2/d3/fdc722a1b61857250a76027d6d73a50182c6d85132ddd65600a8993574ce/azure_cli_profile-2.1.2-py2.py3-none-any.whl\n",
      "Collecting ndg-httpsclient (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/fb/67/c2f508c00ed2a6911541494504b7cac16fe0b0473912568df65fd1801132/ndg_httpsclient-0.5.1-py3-none-any.whl\n",
      "Collecting msrest>=0.5.1 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/40/70e545b7a5b0509273c6fe981118fb64e389fe013504b1c22a24fec4d1d9/msrest-0.6.2-py2.py3-none-any.whl (81kB)\n",
      "Collecting python-dateutil>=2.7.3 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/74/68/d87d9b36af36f44254a8d512cbfc48369103a3b9e474be9bdfe536abfc45/python_dateutil-2.7.5-py2.py3-none-any.whl (225kB)\n",
      "Collecting pytz (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f8/0e/2365ddc010afb3d79147f1dd544e5ee24bf4ece58ab99b16fbb465ce6dc0/pytz-2018.7-py2.py3-none-any.whl (506kB)\n",
      "Collecting azure-graphrbac>=0.40.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/da/a8/3d3d6fe8458b2b07bad10195c79928ea9ba87b5cc0c08903b387dd27c6f0/azure_graphrbac-0.53.0-py2.py3-none-any.whl (108kB)\n",
      "Collecting ruamel.yaml<=0.15.51,>=0.15.35 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d2/7f/9bb3ba89ceab600c4a0ea75d638ea945215ca3458ac6528e0e39fa3254e4/ruamel.yaml-0.15.51-cp36-cp36m-manylinux1_x86_64.whl (640kB)\n",
      "Collecting docker (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e1/58/938fbc7acd98302ca4872f5eab8ab811498e342ab5aec0c1609f22e0aeda/docker-3.6.0-py2.py3-none-any.whl (131kB)\n",
      "Collecting azure-mgmt-authorization>=0.40.0 (from azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a1/71/9a20913e92771b3c23564f1bea54d376d09fb30a75585087c70b769d75c8/azure_mgmt_authorization-0.51.1-py2.py3-none-any.whl (111kB)\n",
      "Collecting azureml-pipeline-steps==1.0.2.* (from azureml-pipeline==1.0.2.*->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/a6/0f/301d8309ff8510774426e27a5fc887ada96cb6f9ff57997d1723ba166d72/azureml_pipeline_steps-1.0.2-py3-none-any.whl\n",
      "Collecting azureml-pipeline-core==1.0.2.* (from azureml-pipeline==1.0.2.*->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/ab/53/2f3f5c8773359c0f0a253d07b977839884e31412f7f2d1ccc82394375b71/azureml_pipeline_core-1.0.2-py3-none-any.whl (125kB)\n",
      "Collecting azureml-train-core==1.0.2.* (from azureml-train==1.0.2.*->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/23/e7/d3d35c00af16a76e01a717b49d2549713c2dd1cd8c1d09d7ff879a9b990c/azureml_train_core-1.0.2-py3-none-any.whl (63kB)\n",
      "Collecting keras==2.1.5 (from azureml-contrib-brainwave==1.0.2.*; extra == \"contrib\"->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/ba/65/e4aff762b8696ec0626a6654b1e73b396fcc8b7cc6b98d78a1bc53b85b48/Keras-2.1.5-py2.py3-none-any.whl (334kB)\n",
      "Collecting Flask<2.0,>=1.0 (from azureml-contrib-services==1.0.2.*; extra == \"contrib\"->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/e7/08578774ed4536d3242b14dacb4696386634607af824ea997202cd0edb4b/Flask-1.0.2-py2.py3-none-any.whl (91kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.11.0,>=1.10.0->tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n",
      "Collecting werkzeug>=0.11.10 (from tensorboard<1.11.0,>=1.10.0->tensorflow-gpu==1.10->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\n",
      "Collecting adal<2.0.0,>=0.6.0 (from msrestazure>=0.4.33->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/2d/2f/14882b8dae0977e85577abde3065c141fb94dbb242adfb80e21797e4f7c9/adal-1.2.0-py2.py3-none-any.whl (52kB)\n",
      "Collecting azure-mgmt-nspkg>=2.0.0 (from azure-mgmt-keyvault>=0.40.0->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b3/c2/af4b47845f27dc7d206ed4908b9e580f8bc94a4b2f3956a0d87c40719d90/azure_mgmt_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting colorama>=0.3.9 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
      "Collecting tabulate<=0.8.2,>=0.7.7 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/12/c2/11d6845db5edf1295bc08b2f488cf5937806586afe42936c3f34c097ebdc/tabulate-0.8.2.tar.gz (45kB)\n",
      "Collecting jmespath (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting paramiko>=2.0.8 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/cf/ae/94e70d49044ccc234bfdba20114fa947d7ba6eb68a2e452d89b920e62227/paramiko-2.4.2-py2.py3-none-any.whl (193kB)\n",
      "Collecting pygments (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/fc/41/4f900a7852e25bb9350b4e3ee8c4aba0ee32abefd401456962b25f954823/Pygments-2.3.0-py2.py3-none-any.whl (845kB)\n",
      "Collecting azure-cli-telemetry (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/4c/da5ebe9300ecdc850031372f81229383c46a70e83dee8e77f58aa6fd0546/azure_cli_telemetry-1.0.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pip in /azureml-envs/azureml_c77fd37935750ffd1124c72fa1618fa3/lib/python3.6/site-packages (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1)) (18.1)\n",
      "Collecting humanfriendly>=4.7 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/79/1e/13d96248e3fcaa7777b61fa889feab44865c85e524bbd667acfa0d8b66e3/humanfriendly-4.17-py2.py3-none-any.whl (72kB)\n",
      "Collecting antlr4-python3-runtime; python_version >= \"3.0\" (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/3e/96/aba01b2948ec67f237cd387c022820835ae0d8db5cab4bd404b351660b5e/antlr4-python3-runtime-4.7.1.tar.gz (111kB)\n",
      "Collecting knack==0.5.1 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/27/46/0a6d7471efcc519e392640f6933c0f644bbf602971e64797108292cb3623/knack-0.5.1-py2.py3-none-any.whl (50kB)\n",
      "Collecting pyopenssl>=17.1.0 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/96/af/9d29e6bd40823061aea2e0574ccb2fcf72bfd6130ce53d32773ec375458c/pyOpenSSL-18.0.0-py2.py3-none-any.whl (53kB)\n",
      "Collecting argcomplete>=1.8.0 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/31/88/ba8d8684a8a27749250c66ff7c2b408fdbc29b50da61200338ff9b2607bf/argcomplete-1.9.4-py2.py3-none-any.whl\n",
      "Collecting pyyaml~=3.13 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/9e/a3/1d13970c3f36777c583f136c136f804d70f500168edc1edea6daa7200769/PyYAML-3.13.tar.gz (270kB)\n",
      "Collecting azure-cli-nspkg>=2.0.0 (from azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/a7/85/601ef6484bf7a722daa76a4383c4ccfd4980b74ed6c2895392f53ed210d5/azure_cli_nspkg-3.0.3-py2.py3-none-any.whl\n",
      "Collecting backports.weakref (from backports.tempfile->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/88/ec/f598b633c3d5ffe267aaada57d961c94fdfa183c5c3ebda2b6d151943db6/backports.weakref-1.0.post1-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests>=2.19.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_c77fd37935750ffd1124c72fa1618fa3/lib/python3.6/site-packages (from requests>=2.19.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1)) (2018.10.15)\n",
      "Collecting idna<2.8,>=2.5 (from requests>=2.19.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl (58kB)\n",
      "Collecting azure-nspkg>=2.0.0 (from azure-storage-nspkg>=3.0.0->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/c4/0c/c562be95a9a2ed52454f598571cf300b1114d0db2aa27f5b8ed3bb9cd0c0/azure_nspkg-3.0.2-py3-none-any.whl\n",
      "Collecting asn1crypto>=0.21.0 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/cd/35485615f45f30a510576f1a56d1e0a7ad7bd8ab5ed7cdc600ef7cd06222/asn1crypto-0.24.0-py2.py3-none-any.whl (101kB)\n",
      "Collecting cffi!=1.11.3,>=1.7 (from cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/6d/c0/47db8f624f3e4e2f3f27be03a93379d1ba16a1450a7b1aacfa0366e2c0dd/cffi-1.11.5-cp36-cp36m-manylinux1_x86_64.whl (421kB)\n",
      "Collecting azure-cli-command-modules-nspkg>=2.0.0 (from azure-cli-profile>=2.0.26->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/c9/cdeeeabc550848e2a07caa66cba28aa057d23b6feaa824ceafd32c3f2226/azure_cli_command_modules_nspkg-2.0.2-py2.py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.1 (from ndg-httpsclient->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/a1/7790cc85db38daa874f6a2e6308131b9953feb1367f2ae2d1123bb93a9f5/pyasn1-0.4.4-py2.py3-none-any.whl (72kB)\n",
      "Collecting requests-oauthlib>=0.5.0 (from msrest>=0.5.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/94/e7/c250d122992e1561690d9c0f7856dadb79d61fd4bdd0e598087dce607f6c/requests_oauthlib-1.0.0-py2.py3-none-any.whl\n",
      "Collecting isodate>=0.6.0 (from msrest>=0.5.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "Collecting websocket-client>=0.32.0 (from docker->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/26/2d/f749a5c82f6192d77ed061a38e02001afcba55fe8477336d26a950ab17ce/websocket_client-0.54.0-py2.py3-none-any.whl (200kB)\n",
      "Collecting docker-pycreds>=0.3.0 (from docker->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
      "Collecting azureml-train-restclients-hyperdrive==1.0.2.* (from azureml-train-core==1.0.2.*->azureml-train==1.0.2.*->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/81/90/3929746fd05c1e221fa082742e84e8a5ddad771af773fdce7f69079c0818/azureml_train_restclients_hyperdrive-1.0.2-py3-none-any.whl\n",
      "Collecting azureml-telemetry==1.0.2.* (from azureml-train-core==1.0.2.*->azureml-train==1.0.2.*->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/c3/9bbba3c3ed4c2443fedca49e443caa26112df47f4414a1b51af0a6cd1ee0/azureml_telemetry-1.0.2-py3-none-any.whl\n",
      "Collecting scipy>=0.14 (from keras==2.1.5->azureml-contrib-brainwave==1.0.2.*; extra == \"contrib\"->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
      "Collecting itsdangerous>=0.24 (from Flask<2.0,>=1.0->azureml-contrib-services==1.0.2.*; extra == \"contrib\"->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/76/ae/44b03b253d6fade317f32c24d100b3b35c2239807046a4c953c7b89fa49e/itsdangerous-1.1.0-py2.py3-none-any.whl\n",
      "Collecting Jinja2>=2.10 (from Flask<2.0,>=1.0->azureml-contrib-services==1.0.2.*; extra == \"contrib\"->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/7f/ff/ae64bacdfc95f27a016a7bed8e8686763ba4d277a78ca76f32659220a731/Jinja2-2.10-py2.py3-none-any.whl (126kB)\n",
      "Collecting click>=5.1 (from Flask<2.0,>=1.0->azureml-contrib-services==1.0.2.*; extra == \"contrib\"->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/fa/37/45185cb5abbc30d7257104c434fe0b07e5a195a6847506c074527aa599ec/Click-7.0-py2.py3-none-any.whl (81kB)\n",
      "Collecting bcrypt>=3.1.3 (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/09/905ec939994e2c49dcffff72f823802557f166b3815ea54c1db3671eed42/bcrypt-3.1.4-cp36-cp36m-manylinux1_x86_64.whl (54kB)\n",
      "Collecting pynacl>=1.0.1 (from paramiko>=2.0.8->azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/27/15/2cd0a203f318c2240b42cd9dd13c931ddd61067809fee3479f44f086103e/PyNaCl-1.3.0-cp34-abi3-manylinux1_x86_64.whl (759kB)\n",
      "Collecting portalocker==1.2.1 (from azure-cli-telemetry->azure-cli-core>=2.0.38->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/57/41/05e79e5516db1cc0c967b3202388cde729f871c871b0a07bf24ff11adfcf/portalocker-1.2.1-py2.py3-none-any.whl\n",
      "Collecting pycparser (from cffi!=1.11.3,>=1.7->cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/68/9e/49196946aee219aead1290e00d1e7fdeab8567783e83e1b9ab5585e6206a/pycparser-2.19.tar.gz (158kB)\n",
      "Collecting oauthlib>=0.6.2 (from requests-oauthlib>=0.5.0->msrest>=0.5.1->azureml-core==1.0.2.*->azureml-defaults->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 1))\n",
      "  Downloading https://files.pythonhosted.org/packages/e6/d1/ddd9cfea3e736399b97ded5c2dd62d1322adef4a72d816f1ed1049d6a179/oauthlib-2.1.0-py2.py3-none-any.whl (121kB)\n",
      "Collecting MarkupSafe>=0.23 (from Jinja2>=2.10->Flask<2.0,>=1.0->azureml-contrib-services==1.0.2.*; extra == \"contrib\"->azureml-sdk[contrib]->-r /azureml-setup/condaenv.eaw0hjt6.requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/08/04/f2191b50fb7f0712f03f064b71d8b4605190f2178ba02e975a87f7b89a0d/MarkupSafe-1.1.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Building wheels for collected packages: termcolor, absl-py, gast, pathspec, SecretStorage, tabulate, antlr4-python3-runtime, pyyaml, pycparser\n",
      "  Running setup.py bdist_wheel for termcolor: started\n",
      "  Running setup.py bdist_wheel for termcolor: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Running setup.py bdist_wheel for absl-py: started\n",
      "  Running setup.py bdist_wheel for absl-py: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/18/ea/5e/e36e1b8739e78cd2eba0a08fdc602c2b16a4b263912af8cb64\n",
      "  Running setup.py bdist_wheel for gast: started\n",
      "  Running setup.py bdist_wheel for gast: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\n",
      "  Running setup.py bdist_wheel for pathspec: started\n",
      "  Running setup.py bdist_wheel for pathspec: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/45/cb/7e/ce6e6062c69446e39e328170524ca8213498bc66a74c6a210b\n",
      "  Running setup.py bdist_wheel for SecretStorage: started\n",
      "  Running setup.py bdist_wheel for SecretStorage: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/4e/5b/1b/be8c8a830a0243af85b2946a0aece2c6743d7f7f946977ed67\n",
      "  Running setup.py bdist_wheel for tabulate: started\n",
      "  Running setup.py bdist_wheel for tabulate: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/85/33/2f6da85d5f10614cbe5a625eab3b3aebfdf43e7b857f25f829\n",
      "  Running setup.py bdist_wheel for antlr4-python3-runtime: started\n",
      "  Running setup.py bdist_wheel for antlr4-python3-runtime: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ef/f6/18/ad300e691236a3408a99edc750484b56e8d6b11b2c38eacb10\n",
      "  Running setup.py bdist_wheel for pyyaml: started\n",
      "  Running setup.py bdist_wheel for pyyaml: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/ad/da/0c/74eb680767247273e2cf2723482cb9c924fe70af57c334513f\n",
      "  Running setup.py bdist_wheel for pycparser: started\n",
      "  Running setup.py bdist_wheel for pycparser: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/f2/9a/90/de94f8556265ddc9d9c8b271b0f63e57b26fb1d67a45564511\n",
      "Successfully built termcolor absl-py gast pathspec SecretStorage tabulate antlr4-python3-runtime pyyaml pycparser\n",
      "\u001b[91mazure-cli-core 2.0.52 has requirement wheel==0.30.0, but you'll have wheel 0.32.3 which is incompatible.\n",
      "\u001b[0m\u001b[91mtensorflow-gpu 1.10.0 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.15.4 which is incompatible.\n",
      "\u001b[0mInstalling collected packages: azure-common, PyJWT, asn1crypto, pycparser, cffi, idna, six, cryptography, chardet, urllib3, requests, python-dateutil, adal, oauthlib, requests-oauthlib, isodate, msrest, msrestazure, azure-nspkg, azure-mgmt-nspkg, azure-mgmt-keyvault, jsonpickle, azure-storage-common, azure-storage-blob, pathspec, azure-mgmt-containerregistry, colorama, tabulate, jmespath, pyasn1, bcrypt, pynacl, paramiko, pygments, azure-cli-nspkg, portalocker, applicationinsights, azure-cli-telemetry, azure-mgmt-resource, humanfriendly, antlr4-python3-runtime, argcomplete, pyyaml, knack, pyopenssl, azure-cli-core, backports.weakref, backports.tempfile, azure-storage-nspkg, SecretStorage, azure-mgmt-storage, contextlib2, azure-cli-command-modules-nspkg, azure-cli-profile, ndg-httpsclient, pytz, azure-graphrbac, ruamel.yaml, websocket-client, docker-pycreds, docker, azure-mgmt-authorization, azureml-core, azureml-defaults, numpy, h5py, pillow, tqdm, azureml-train-restclients-hyperdrive, azureml-telemetry, azureml-train-core, azureml-pipeline-core, azureml-pipeline-steps, azureml-pipeline, azureml-train, azureml-contrib-tensorboard, azureml-contrib-server, grpcio, scipy, keras, azureml-contrib-brainwave, werkzeug, itsdangerous, MarkupSafe, Jinja2, click, Flask, azureml-contrib-services, azureml-contrib-run, azureml-sdk, setuptools, termcolor, protobuf, markdown, tensorboard, absl-py, astor, gast, tensorflow-gpu\n",
      "  Found existing installation: setuptools 40.6.2\n",
      "    Uninstalling setuptools-40.6.2:\n",
      "      Successfully uninstalled setuptools-40.6.2\n",
      "Successfully installed Flask-1.0.2 Jinja2-2.10 MarkupSafe-1.1.0 PyJWT-1.7.0 SecretStorage-2.3.1 absl-py-0.6.1 adal-1.2.0 antlr4-python3-runtime-4.7.1 applicationinsights-0.11.7 argcomplete-1.9.4 asn1crypto-0.24.0 astor-0.7.1 azure-cli-command-modules-nspkg-2.0.2 azure-cli-core-2.0.52 azure-cli-nspkg-3.0.3 azure-cli-profile-2.1.2 azure-cli-telemetry-1.0.0 azure-common-1.1.16 azure-graphrbac-0.53.0 azure-mgmt-authorization-0.51.1 azure-mgmt-containerregistry-2.4.0 azure-mgmt-keyvault-1.1.0 azure-mgmt-nspkg-3.0.2 azure-mgmt-resource-2.0.0 azure-mgmt-storage-3.1.0 azure-nspkg-3.0.2 azure-storage-blob-1.4.0 azure-storage-common-1.4.0 azure-storage-nspkg-3.1.0 azureml-contrib-brainwave-1.0.2 azureml-contrib-run-1.0.2 azureml-contrib-server-1.0.2 azureml-contrib-services-1.0.2 azureml-contrib-tensorboard-1.0.2 azureml-core-1.0.2 azureml-defaults-1.0.2 azureml-pipeline-1.0.2 azureml-pipeline-core-1.0.2 azureml-pipeline-steps-1.0.2 azureml-sdk-1.0.2 azureml-telemetry-1.0.2 azureml-train-1.0.2 azureml-train-core-1.0.2 azureml-train-restclients-hyperdrive-1.0.2 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-3.1.4 cffi-1.11.5 chardet-3.0.4 click-7.0 colorama-0.4.1 contextlib2-0.5.5 cryptography-2.4.2 docker-3.6.0 docker-pycreds-0.4.0 gast-0.2.0 grpcio-1.17.0 h5py-2.8.0 humanfriendly-4.17 idna-2.7 isodate-0.6.0 itsdangerous-1.1.0 jmespath-0.9.3 jsonpickle-1.0 keras-2.1.5 knack-0.5.1 markdown-3.0.1 msrest-0.6.2 msrestazure-0.5.1 ndg-httpsclient-0.5.1 numpy-1.15.4 oauthlib-2.1.0 paramiko-2.4.2 pathspec-0.5.9 pillow-5.3.0 portalocker-1.2.1 protobuf-3.6.1 pyasn1-0.4.4 pycparser-2.19 pygments-2.3.0 pynacl-1.3.0 pyopenssl-18.0.0 python-dateutil-2.7.5 pytz-2018.7 pyyaml-3.13 requests-2.20.1 requests-oauthlib-1.0.0 ruamel.yaml-0.15.51 scipy-1.1.0 setuptools-39.1.0 six-1.11.0 tabulate-0.8.2 tensorboard-1.10.0 tensorflow-gpu-1.10.0 termcolor-1.1.0 tqdm-4.28.1 urllib3-1.23 websocket-client-0.54.0 werkzeug-0.14.1\n",
      "#\n",
      "# To activate this environment, use:\n",
      "# > source activate /azureml-envs/azureml_c77fd37935750ffd1124c72fa1618fa3\n",
      "#\n",
      "# To deactivate an active environment, use:\n",
      "# > source deactivate\n",
      "#\n",
      "\n",
      "\u001b[91m\n",
      "\u001b[0m ---> 1f136d54f0f1\n",
      "Removing intermediate container bbacc62f6d24\n",
      "Step 9/13 : ENV PATH /azureml-envs/azureml_c77fd37935750ffd1124c72fa1618fa3/bin:$PATH\n",
      " ---> Running in 4a9f7a31408d\n",
      " ---> 82293c6e1418\n",
      "Removing intermediate container 4a9f7a31408d\n",
      "Step 10/13 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_c77fd37935750ffd1124c72fa1618fa3/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 0fac628e24c1\n",
      " ---> 90b4f5686ec1\n",
      "Removing intermediate container 0fac628e24c1\n",
      "Step 11/13 : COPY azureml-setup/spark_cache.py azureml-setup/log4j.properties /azureml-setup/\n",
      " ---> 44a8429e30b0\n",
      "Step 12/13 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit \"--repositories\" \"https://mmlspark.azureedge.net/maven\" \"--packages\" \"com.microsoft.ml.spark:mmlspark_2.11:0.12\" \"--conf\" \"spark.app.name=Azure ML Experiment\" \"--conf\" \"spark.yarn.maxAppAttempts=1\" \"--driver-java-options\" \"-Dlog4j.configuration=file:./azureml-setup/log4j.properties\" \"--conf\" \"spark.eventLog.enabled=true\" \"--conf\" \"spark.eventLog.dir=./azureml-logs\" /azureml-setup/spark_cache.py'; fi\n",
      " ---> Running in b5cb923228c3\n",
      " ---> 4cbeda430d89\n",
      "Removing intermediate container b5cb923228c3\n",
      "Step 13/13 : CMD bash\n",
      " ---> Running in 3355cf21d3bf\n",
      " ---> 2fa5ad859d83\n",
      "Removing intermediate container 3355cf21d3bf\n",
      "Successfully built 2fa5ad859d83\n",
      "Successfully tagged jkamlslaacrizqtrwph.azurecr.io/azureml/azureml_e91631b22e17e89880cec955207fb48b:latest\n",
      "Removing any dangling images\n",
      "Docker build took 447.2351589202881 seconds\n",
      "Logging into acr jkamlslaacrizqtrwph.azurecr.io to do docker push\n",
      "Login Succeeded\n",
      "9e74084b4dc1: Pushed\n",
      "f89e99e8dcc1: Pushed\n",
      "802f3c00f593: Pushed\n",
      "ce619be2681d: Pushed\n",
      "e7ff3c8d56c2: Pushed\n",
      "150ddd7a1544: Pushed\n",
      "75b79e19929c: Pushed\n",
      "4775b2f378bb: Pushed\n",
      "883eafdbe580: Pushed\n",
      "19d043c86cbc: Pushed\n",
      "2fc9fc8da07e: Pushed\n",
      "8823818c4748: Pushed\n",
      "db9d63ec4abf: Pushed\n",
      "08399dc0dc8a: Pushed\n",
      "9327cce3c43e: Pushed\n",
      "latest: digest: sha256:ec4e7fe61c4a5e15de78a1bd2f02b19786dc28446b536e854f29e5f7a6d70599 size: 3672\n",
      "Removing login credentials for jkamlslaacrizqtrwph.azurecr.io\n",
      "Docker push took 597.8616948127747 seconds\n",
      "Not logged in to jkamlslaacrizqtrwph.azurecr.io\n",
      "Docker logout(s) took 0.01620769500732422 seconds\n",
      "Removing image with name jkamlslaacrizqtrwph.azurecr.io/azureml/azureml_e91631b22e17e89880cec955207fb48b\n",
      "Untagged: jkamlslaacrizqtrwph.azurecr.io/azureml/azureml_e91631b22e17e89880cec955207fb48b:latest\n",
      "Untagged: jkamlslaacrizqtrwph.azurecr.io/azureml/azureml_e91631b22e17e89880cec955207fb48b@sha256:ec4e7fe61c4a5e15de78a1bd2f02b19786dc28446b536e854f29e5f7a6d70599\n",
      "Deleted: sha256:2fa5ad859d83fa9fe4edad4b6ec2d53f42441de67dd1723536c6dc3681ddd014\n",
      "Deleted: sha256:4cbeda430d89bcecb3604d8194947281e8ee396873f04b10e4dfa31ed6a4f7f4\n",
      "Deleted: sha256:44a8429e30b0431db8e0a901d27ddd4357222f516f510c01f3c5981e5bfc8e4e\n",
      "Deleted: sha256:2ebb59df3ad8a799b007c2528607de4bfcb92db04381317cd31ee11bb481e3f1\n",
      "Deleted: sha256:90b4f5686ec10953f4af1ee122da2060cb27ca38ead0faf35e995428bda4d66e\n",
      "Deleted: sha256:82293c6e1418ba93d02e2243ae72fef5c7e0a45982f45818cfd5fa49723b037d\n",
      "Deleted: sha256:1f136d54f0f168004f5b5ea91a615ff3334ad7650ed63e970f5da5beb7785149\n",
      "Deleted: sha256:1ce14b43549ac574d76516820d723e131dd73b77273e0fd50472aa2677dbe2a7\n",
      "Deleted: sha256:af128969104feba37f20cbf03f6dc348692c75ab1effa61187dd8bb8b658fa8a\n",
      "Deleted: sha256:5f9b001960e9a4622097c2587aa46d995635fcaea7ef07bb63f91a8f9259e151\n",
      "Deleted: sha256:823d9a8295750e629ca2dc507099151f86d4bd81ecf04800accfeb4eade074b8\n",
      "Deleted: sha256:123aaeb628674e86718cf81b8fd81d01a474ec3a0cc4c1c837c597cf131c0c27\n",
      "Deleted: sha256:0ec5ee962a49f9e4b8718d9c75f33feb57df04165b80b9c7cf52c716ab10fc7e\n",
      "Deleted: sha256:2cd5ad3e211af9c2c7dd05e4fec6741a651352b45a2af3592553b2b6fb877e02\n",
      "Deleted: sha256:0f82961536e871cffcee3c30d642471dda34b94789de817ff16cd15caab1b539\n",
      "Deleted: sha256:ad467dbf2d7171bfe25ddcc28ad5247acde8d181befa476434eb46a644e89763\n",
      "Deleted: sha256:b9aa16dec9ecbc1ac057ccade0faeb7a247de1b86b12105cfcfe226d94f73077\n",
      "Total task took 1052.9174211025238 secs\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "Streaming log file azureml-logs/80_driver_log.txt\n"
     ]
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the run, AML copied the output bottleneck files to the default datastore. You can verify it using Azure Portal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "The run has completed. The next step is to train a small Fully Connected Neural Network using engineered bottleneck features.\n",
    "\n",
    "We will use AML feature called `Hyperdrive` to fine tune hyperparameters of the neural network. `Hyperdrive` will utilize Azure ML Compute GPU cluster to run and evaluate concurrent training jobs. After the model is fine tuned, the best version will be registered in AML Model Registry.\n",
    "\n",
    "### Create training script\n",
    "\n",
    "In the training script, we use Tensorflow.Keras to define and train a simple fully connected neural network.\n",
    "\n",
    "The network has one hidden layer. The input to the network is a vector of 2048 floating point numbers - the bottleneck features created in the previous step. The output layer consists of 6 units - representing six land type classes. To control overfitting the network uses a Dropout layer between the hidden layer and the output layer and L1 and L2 regularization in the output layer.\n",
    "\n",
    "The number of units in the hidden layer, L1 and L2 values, and batch size are all tuneable hyperparameters. The Dropout ratio is fixed at 0.5.\n",
    "\n",
    "Since the bottleneck feature files are small (as compared to original image datasets) they can be loaded into memory all at once.\n",
    "\n",
    "The trained model will be saved into the ./outputs folder. This is one of the special folders in AML. The other one is the ./logs folder. The content in these folders is automatically uploaded to the run history.\n",
    "\n",
    "The script uses AML Run object to track two performane measures: training accuracy and validation accuracy. The metrics are captured at the end of each epoch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "script_name = 'train.py'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Flatten, Input\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import h5py\n",
    "\n",
    "\n",
    "# Create custom callback to track accuracy measures in AML Experiment\n",
    "class RunCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, run):\n",
    "        self.run = run\n",
    "        \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.run.log(name=\"training_acc\", value=float(logs.get('acc')))\n",
    "        self.run.log(name=\"validation_acc\", value=float(logs.get('val_acc')))\n",
    "\n",
    "\n",
    "# Define network\n",
    "def fcn_classifier(input_shape=(2048,), units=512, classes=6,  l1=0.01, l2=0.01):\n",
    "    features = Input(shape=input_shape)\n",
    "    x = Dense(units, activation='relu')(features)\n",
    "    x = Dropout(0.5)(x)\n",
    "    y = Dense(classes, activation='softmax', kernel_regularizer=l1_l2(l1=l1, l2=l2))(x)\n",
    "    model = Model(inputs=features, outputs=y)\n",
    "    model.compile(optimizer='adadelta', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Training regime\n",
    "def train_evaluate(run):\n",
    "   \n",
    "    print(\"Loading bottleneck features\")\n",
    "    train_file_name = os.path.join(FLAGS.data_folder, FLAGS.train_file_name)\n",
    "    \n",
    "    # Load bottleneck training features and labels\n",
    "    with h5py.File(train_file_name, \"r\") as hfile:\n",
    "        features = np.array(hfile.get('features'))\n",
    "        labels = np.array(hfile.get('labels'))\n",
    "        \n",
    "    \n",
    "        \n",
    "    # Split the data into training and validation partitions   \n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(features, labels,\n",
    "                                                               test_size=0.1,\n",
    "                                                               shuffle=True,\n",
    "                                                               stratify=labels)\n",
    "        \n",
    "    # Convert labels into one-hot encoded format\n",
    "    y_train = to_categorical(y_train, num_classes=6)\n",
    "    y_validation = to_categorical(y_validation, num_classes=6)\n",
    "    \n",
    "    # Create a network\n",
    "    model = fcn_classifier(input_shape=(2048,), units=FLAGS.units, l1=FLAGS.l1, l2=FLAGS.l2)\n",
    "    \n",
    "    # Create AML tracking callback\n",
    "    run_callback = RunCallback(run)\n",
    "    \n",
    "    # Start training\n",
    "    print(\"Starting training\")\n",
    "    model.fit(X_train, y_train,\n",
    "          batch_size=FLAGS.batch_size,\n",
    "          epochs=FLAGS.epochs,\n",
    "          shuffle=True,\n",
    "          validation_data=(X_validation, y_validation),\n",
    "          callbacks=[run_callback])\n",
    "          \n",
    "    # Save the trained model to outputs which is a standard folder expected by AML\n",
    "    print(\"Training completed.\")\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    model_file = os.path.join('outputs', 'aerial_fcnn_classifier.hd5')\n",
    "    print(\"Saving model to: {0}\".format(model_file))\n",
    "    model.save(model_file)\n",
    "    \n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "# Default global parameters\n",
    "tf.app.flags.DEFINE_integer('batch_size', 32, \"Number of images per batch\")\n",
    "tf.app.flags.DEFINE_integer('epochs', 10, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_integer('units', 512, \"Number of epochs to train\")\n",
    "tf.app.flags.DEFINE_float('l1', 0.01, \"l1 regularization\")\n",
    "tf.app.flags.DEFINE_float('l2', 0.01, \"l2 regularization\")\n",
    "tf.app.flags.DEFINE_string('data_folder', './bottleneck', \"Folder with bottleneck features and labels\")\n",
    "tf.app.flags.DEFINE_string('train_file_name', 'aerial_bottleneck_resnet50.h5', \"Training file name\")\n",
    "\n",
    "def main(argv=None):\n",
    "    \n",
    "    # get hold of the current run\n",
    "    run = Run.get_submitted_run()\n",
    "    train_evaluate(run)\n",
    "  \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    tf.app.run()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure datastor\n",
    "\n",
    "The bottleneck files have been uploaded to the workspace's default datastore during the previous step. We will mount the store on the nodes of the cluster.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Datastore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(\"Using the default datastore for training data: \")\n",
    "print(ds.name, ds.datastore_type, ds.account_name, ds.container_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a test run on a single node of the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data_folder': ds.path('bottleneck_features').as_download(),\n",
    "    '--training_file_name': 'aerial_bottleneck_resnet50_brainwave.h5',\n",
    "    '--l1': 0.001,\n",
    "    '--l2': 0.001,\n",
    "    '--units': 512,\n",
    "    '--epochs': 10\n",
    "}\n",
    "\n",
    "\n",
    "pip_packages = ['h5py','pillow', 'scikit-learn', 'tensorflow-gpu']\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=bai_compute_target,\n",
    "                entry_script=script_name,\n",
    "                pip_packages=pip_packages,\n",
    "                use_gpu=True,\n",
    "                node_count=1,\n",
    "                process_count_per_node=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\"Compute target\": \"BAI\", \"Run Type\": \"Test drive\"}\n",
    "run = exp.submit(est, tags=tags)\n",
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure `Hyperdrive`\n",
    "\n",
    "As noted before, our network has 5 hyperparameters:\n",
    "\n",
    "- Number of units in the hidden layer\n",
    "- L1 and L2 regularization\n",
    "- mini-batch size, and\n",
    "- dropout ratio\n",
    "\n",
    "As we have limited time to complete the lab, we are going to limit a number of hyperparameter combinations to try. We will use a fixed batch-size and dropout ratio and focus on hidden layer units and L1 and L2 regularization.\n",
    "\n",
    "*Hyperdrive* supports many strategies for sampling the hyperparameter space. In this lab, we are going to use the simplest one - grid sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "ps = GridParameterSampling(\n",
    "    {\n",
    "        '--units': choice(256, 512),\n",
    "        '--l1': choice(0.001, 0.01, 0.05),\n",
    "        '--l2': choice(0.001, 0.01, 0.05)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **Estimator** object to configure the training job. Note how we pass the location of the bottleneck files to the estimator. The job will run on GPU VMs and as such we need to use the GPU version of Tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data_folder': ds.path('bottleneck_features').as_download(),\n",
    "    '--training_file_name': 'aerial_bottleneck_resnet50_brainwave.h5',\n",
    "    '--epochs': 50\n",
    "}\n",
    "\n",
    "pip_packages = ['h5py','pillow', 'scikit-learn', 'tensorflow-gpu']\n",
    "\n",
    "est = Estimator(source_directory=script_folder,\n",
    "                script_params=script_params,\n",
    "                compute_target=bai_compute_target,\n",
    "                entry_script=script_name,\n",
    "                pip_packages=pip_packages,\n",
    "                use_gpu=True,\n",
    "                node_count=1,\n",
    "                process_count_per_node=1\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Hyperdrive* supports early termination policies to limit exploration of hyperparameter combinations that don't show promise of helping reach the target metric. This feature is especially useful when traversing large hyperparameter spaces. Since we are going to run a small number of jobs we will not apply early termination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = NoTerminationPolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to configure a run configuration object, and specify the primary metric as *validation_acc* that's recorded in our training runs. If you go back to visit the training script, you will notice that this value is being logged after every run. We also want to tell the service that we are looking to maximizing this value. We also set the number of total runs to 12, and maximal concurrent job to 4, which is the same as the number of nodes in our computer cluster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htc = HyperDriveRunConfig(estimator=est, \n",
    "                          hyperparameter_sampling=ps,\n",
    "                          policy=policy,\n",
    "                          primary_metric_name='validation_acc', \n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                          max_total_runs=12,\n",
    "                          max_concurrent_runs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's launch the hyperparameter tuning job.\n",
    "\n",
    "The first run takes longer as the system has to prepare and deploy a docker image with training job runtime dependencies. As long as the dependencies don't change the following runs will be much faster.\n",
    "\n",
    "Here is what's happening whie you wait.\n",
    "\n",
    "- **Image creation**: A Docker image is created matching the Python environment specified by the estimator. The image is uploaded to the workspace. This stage happens once for each Python environment since the container is cached for subsequent runs. During image creation, logs are streamed to the run history. You can monitor the image creation progress using these logs.\n",
    "\n",
    "- **Scaling**: If the remote cluster requires more nodes to execute the run than currently available, additional nodes are added automatically.\n",
    "\n",
    "- **Running**: In this stage, the necessary scripts and files are sent to the compute target, then data stores are mounted/copied, then the entry_script is run. While the job is running, stdout and the ./logs directory are streamed to the run history. You can monitor the run's progress using these logs.\n",
    "\n",
    "- **Post-Processing**: The ./outputs directory of the run is copied over to the run history in your workspace so you can access these results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\"Training: \"Hyperdrive\"}\n",
    "\n",
    "hdr = exp.submit(config=htc, tags=tags)\n",
    "hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.widgets import RunDetails\n",
    "RunDetails(hdr).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdr.wait_for_completion(show_output=False) # specify True for a verbose log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find and register best model\n",
    "When all jobs finish, we can find out the one that has the highest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = hdr.get_best_run_by_primary_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run_metrics = best_run.get_metrics()\n",
    "parameter_values = best_run.get_details()['runDefinition']['Arguments']\n",
    "\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print('\\n Validation Accuracy:', best_run_metrics['validation_acc'])\n",
    "print('\\n Units:',parameter_values[7])\n",
    "print('\\n L1:',parameter_values[9])\n",
    "print('\\n L2:',parameter_values[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the output of the best run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run.get_file_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register model\n",
    "The last step in the training script wrote the file `aerial_fcnn_classifier.hd5` in the `outputs` directory. As noted before, `outputs` is a special directory in that all content in this  directory is automatically uploaded to your workspace.  This content appears in the run record in the experiment under your workspace. \n",
    "\n",
    "You can register the model so that it can be later queried, examined and deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = best_run.register_model(model_name='aerial_classifier', \n",
    "                                model_path='outputs/aerial_fcnn_classifier.hd5')\n",
    "print(model.name, model.id, model.version, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up resources\n",
    "Before you move to the next step, delete the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bai_compute_target.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
