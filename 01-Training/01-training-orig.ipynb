{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Training a Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will setup the Azure Machine Learning service and use it for tracking training of a `scikit-learn` model.\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/amlarch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the lab datasets\n",
    "The following cell will download the dataset used by this lab. Click into the following cell and use `Shift + Enter` to execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create a temporary folder to store locally relevant content for this notebook\n",
    "datasetsFolderName = '../datasets'\n",
    "os.makedirs(datasetsFolderName, exist_ok=True)\n",
    "print('Content files will be saved to {0}'.format(datasetsFolderName))\n",
    "\n",
    "filesToDownload = ['UsedCars_Clean.csv', 'UsedCars_Affordability.csv']\n",
    "\n",
    "for fileToDownload in filesToDownload:\n",
    "  downloadCommand = 'wget -O ''{0}/{1}'' ''https://databricksdemostore.blob.core.windows.net/data/aml-labs/{1}'''.format(datasetsFolderName, fileToDownload)\n",
    "  print(downloadCommand)\n",
    "  os.system(downloadCommand)\n",
    "  \n",
    "#List all downloaded files\n",
    "os.listdir(datasetsFolderName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell loads the sampled dataset. Take a moment to look at the data loaded into the Pandas Dataframe - it contains data about used cars such as the price (in dollars), age (in years), KM (kilometers driven) and other attributes like weather it is automatic transimission, the number of doors, and the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pathToCsvFile = os.path.join(datasetsFolderName, 'UsedCars_Clean.csv')\n",
    "df = pd.read_csv(pathToCsvFile, delimiter=',')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try and build a model that can answer the question \"Can I afford a car that is X months old and has Y kilometers on it, given I have $12,000 to spend?\". We will engineer the label for affordable. Execute the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the affordable feature\n",
    "\n",
    "df['Affordable'] = np.where(df['Price']<12000, 1, 0)\n",
    "df_affordability = df[[\"Age\",\"KM\", \"Affordable\"]]\n",
    "print(df_affordability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train a Logistic Regression model using `sckit-learn`. This type of model requires us to standardize the scale of our training features Age and KM, so we use the `StandardScaler` from Scikit-Learn to transform these features so that they have values centered with a mean around 0 (mostly between -2.96 and 1.29). Select Step 3 and execute the code. Observe the difference in min and max values between the un-scaled and scaled Dataframes. When we use Sci-Kit Learn, these models are trained on the driver node. Execute the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numeric feature values\n",
    "\n",
    "X = df_affordability[[\"Age\", \"KM\"]].values\n",
    "y = df_affordability[[\"Affordable\"]].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.astype(float))\n",
    "\n",
    "print(pd.DataFrame(X).describe().round(2))\n",
    "print(pd.DataFrame(X_scaled).describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model by fitting a LogisticRegression against the scaled input features (X_scaled) and the labels (y). Execute the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Logistic Regression\n",
    "\n",
    "from sklearn import linear_model\n",
    "# Create a linear model for Logistic Regression\n",
    "clf = linear_model.LogisticRegression(C=1)\n",
    "\n",
    "# Flatten labels\n",
    "y = np.ravel(y)\n",
    "\n",
    "# we create an instance of Classifier and fit the data.\n",
    "clf.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try prediction - if you set the age to 60 months and km to 40,000, does the model predict you can afford the car? Execute the cell and find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the trained model's prediction\n",
    "\n",
    "age = 60\n",
    "km = 40000\n",
    "\n",
    "scaled_input = scaler.transform([[age, km]])\n",
    "prediction = clf.predict(scaled_input)\n",
    "\n",
    "print(\"Can I afford a car that is {} month(s) old with {} KM's on it?\".format(age,km))\n",
    "print(\"Yes (1)\" if prediction[0] == 1 else \"No (0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get a sense for how accurate the model is. Execute the following cell. What was your model's accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measure the model's performance\n",
    "\n",
    "scaled_inputs = scaler.transform(X.astype(float))\n",
    "predictions = clf.predict(scaled_inputs)\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y, predictions)\n",
    "print(\"Model Accuracy: {}\".format(score.round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key hyperparameter of logistic regression is regularization strength. To be precise it is the inverse of regularization strength in `sklearn`. In the next cell, you define a method that allows you to experiment with different values of `C`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a method to experiment with different values of C\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "full_X = df_affordability[[\"Age\", \"KM\"]]\n",
    "full_Y = df_affordability[[\"Affordable\"]]\n",
    "\n",
    "def train_eval_model(full_X, full_Y,training_set_percentage, C):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, train_size=training_set_percentage, random_state=42)\n",
    "    \n",
    "    # Flatten labels\n",
    "    train_Y = np.ravel(train_Y)\n",
    "    test_Y = np.ravel(test_Y)\n",
    "    \n",
    "    # Convert to float\n",
    "    train_X = train_X.astype(float)\n",
    "    test_X = test_X.astype(float)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(train_X)\n",
    "    clf = linear_model.LogisticRegression(C=C, solver='lbfgs')\n",
    "    clf.fit(X_scaled, train_Y)\n",
    "\n",
    "    scaled_inputs = scaler.transform(test_X)\n",
    "    predictions = clf.predict(scaled_inputs)\n",
    "    score = accuracy_score(test_Y, predictions)\n",
    "\n",
    "    return (clf, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Azure Machine Learning to log performance metrics\n",
    "In the steps that follow, you will train multiple models using different values of C and observe the impact on performance (accuracy). Each time you create a new model, you are executing a Run in the terminology of Azure Machine Learning service. In this case, you will create one Experiment and execute multiple Runs within it, each with different value of C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to quickly verify you have the Azure Machine Learning SDK installed on your cluster. If you get a version number back without error, you are ready to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify AML SDK Installed\n",
    "\n",
    "import azureml.core\n",
    "print(\"SDK Version:\", azureml.core.VERSION)\n",
    "\n",
    "# import the Workspace class \n",
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Azure Machine Learning entities are organized within a Workspace. You can create an AML Workspace in the Azure Portal, but as the code in the following cell shows, you can also create a Workspace directly from code. Set the values for `subscription_id`, `resource_group`, `workspace_name` and `workspace_region` as directed by the comments. Execute Step 9. You will be prompted to log in to your Azure Subscription by the command output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a workspace\n",
    "\n",
    "#Provide the Subscription ID of your existing Azure subscription\n",
    "subscription_id = \"<your subscription>\"\n",
    "\n",
    "#Provide values for the Resource Group and Workspace that will be created\n",
    "resource_group = \"<your resource group>\"\n",
    "workspace_name = \"<your workspace name>\"\n",
    "workspace_region = \"<your region>\"\n",
    "\n",
    "ws = Workspace.create(\n",
    "    name = workspace_name,\n",
    "    subscription_id = subscription_id,\n",
    "    resource_group = resource_group, \n",
    "    location = workspace_region,\n",
    "    exist_ok = True)\n",
    "\n",
    "print(\"Workspace Provisioning complete.\")\n",
    "ws.get_details()\n",
    "ws.write_config('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin capturing metrics, you must first create an Experiment and then call `start_logging()` on that Experiment. The return value of this call is a Run. This root run can have other child runs. When you are finished with an experiment run, use `complete()` to close out the root run. Execute the following cell to train four different models using differing amounts of training data and log the results to Azure Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an experiment and log metrics for multiple training runs\n",
    "\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "# start a training run by defining an experiment\n",
    "myexperiment = Experiment(ws, \"usedcars_training_local\")\n",
    "root_run = myexperiment.start_logging()\n",
    "\n",
    "training_set_percentage = 0.25\n",
    "C = 2\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage, C)\n",
    "print(\"With C={}, model accuracy reached {}\".format(C, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"C\", C)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "C = 1\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage, C)\n",
    "print(\"With C={}, model accuracy reached {}\".format(C, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"C\", C)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "C = 0.75\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage, C)\n",
    "print(\"With C={}, model accuracy reached {})\".format(C, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"C\", C)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "C = 0.5\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage, C)\n",
    "print(\"With C={}, model accuracy reached {})\".format(C, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"C\", C)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "# Close out the experiment\n",
    "root_run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have captured history for various runs, you can review the runs. You could use the Azure Portal for this - go to the Azure Portal, find your Azure Machine Learning Workspace, select Experiments and select the UsedCars_Experiment. However, in this case we will use the AML SDK to query for the runs. Execute the following cell to view the runs and their status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review captured runs\n",
    "# Go to the Azure Portal, find your Azure Machine Learning Workspace, select Experiments and select the UsedCars_Experiment\n",
    "\n",
    "# You can also query the run history using the SDK.\n",
    "# The following command lists all of the runs for the experiment\n",
    "runs = [r for r in root_run.get_children()]\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train remotely using Azure ML Compute\n",
    "\n",
    "Up until now, all of your training was executed locally on the same machine running Jupyter. Now you will execute the same logic targeting a remote Azure ML Compute, which you will provision from code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Azure ML Compute cluster\n",
    "\n",
    "# Create Azure ML cluster\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cpu-bai-cluster\"\n",
    "cluster_min_nodes = 1\n",
    "cluster_max_nodes = 3\n",
    "vm_size = \"STANDARD_DS11_V2\"\n",
    "\n",
    "if cluster_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[cluster_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found existing compute target, using this compute target instead of creating:  ' + cluster_name)\n",
    "    else:\n",
    "        print(\"Error: A compute target with name \",cluster_name,\" was found, but it is not of type AmlCompute.\")\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size, \n",
    "                                                                min_nodes = cluster_min_nodes, \n",
    "                                                                max_nodes = cluster_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current BatchAI cluster status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your cluster ready, you need to upload the training data to the default DataStore for your AML Workspace (which uses Azure Storage). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset to the DataStore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "ds.upload(src_dir='../datasets', target_path='used_cars', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will need to create a training script that is similar to the code you have executed locally to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model \n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "# let user feed in 2 parameters, the location of the data files (from datastore), and the training set percentage to use\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "parser.add_argument('--training-set-percentage', type=float, dest='training_set_percentage', default=0.25, help='percentage of dataset to use for training')\n",
    "parser.add_argument('--C', type=float, dest='C', default=1, help='regularization')\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_folder = os.path.join(args.data_folder, 'used_cars')\n",
    "print('Data folder:', data_folder)\n",
    "data_csv_path = os.path.join(data_folder, 'UsedCars_Clean.csv')\n",
    "print('Path to CSV file dataset:' + data_csv_path)\n",
    "\n",
    "# Load the data\n",
    "#df = pd.read_csv('UsedCars_Clean.csv', delimiter=',')\n",
    "df = pd.read_csv(data_csv_path)\n",
    "df['Affordable'] = np.where(df['Price']<12000, 1, 0)\n",
    "df_affordability = df[[\"Age\",\"KM\", \"Affordable\"]]\n",
    "\n",
    "\n",
    "# Now experiment with different training subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "full_X = df_affordability[[\"Age\", \"KM\"]]\n",
    "full_Y = df_affordability[[\"Affordable\"]]\n",
    "\n",
    "def train_eval_model(full_X, full_Y,training_set_percentage, C):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, train_size=training_set_percentage, random_state=42)\n",
    "    \n",
    "    # Flatten labels\n",
    "    train_Y = np.ravel(train_Y)\n",
    "    test_Y = np.ravel(test_Y)\n",
    "    \n",
    "    # Convert to float\n",
    "    train_X = train_X.astype(float)\n",
    "    test_X = test_X.astype(float)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(train_X)\n",
    "    clf = linear_model.LogisticRegression(C=C, solver='lbfgs')\n",
    "    clf.fit(X_scaled, train_Y)\n",
    "\n",
    "    scaled_inputs = scaler.transform(test_X)\n",
    "    predictions = clf.predict(scaled_inputs)\n",
    "    score = accuracy_score(test_Y, predictions)\n",
    "\n",
    "    return (clf, score)\n",
    "\n",
    "# Acquire the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "training_set_percentage = args.training_set_percentage\n",
    "C = args.C\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage, C)\n",
    "print(\"With C={}, model accuracy reached {})\".format(C, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"C\", C)\n",
    "run.log(\"Accuracy\", score)\n",
    "\n",
    "\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an estimator that descrives the configuration of the job that will execute your model training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create estimator\n",
    "#############################\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "    '--training-set-percentage': 0.3,\n",
    "    '--C': 2\n",
    "}\n",
    "\n",
    "est_config = Estimator(source_directory=script_folder,\n",
    "                       script_params=script_params,\n",
    "                       compute_target=compute_target,\n",
    "                       entry_script='train.py',\n",
    "                       conda_packages=['scikit-learn', 'pandas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the job using the submit() method of the Experiment object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Execute the estimator job\n",
    "#####################################\n",
    "\n",
    "# Create new experiment\n",
    "from azureml.core import Experiment\n",
    "experiment_name = \"usedcars_training_amlcompute\"\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "run = exp.submit(config=est_config)\n",
    "run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can monitor the job through Azure Portal or using AML Jupyter Widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll for job status\n",
    "run.wait_for_completion(show_output=True)  # value of True will display a verbose, streaming log\n",
    "\n",
    "# Examine the recorded metrics from the run\n",
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "01 model training",
  "notebookId": 863281121960369
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
