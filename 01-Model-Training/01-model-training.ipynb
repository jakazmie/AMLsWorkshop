{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Training a Machine Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will setup the Azure Machine Learning service and use it for tracking training of a `scikit-learn` model.\n",
    "\n",
    "![AML Arch](https://github.com/jakazmie/images-for-hands-on-labs/raw/master/amlarch.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the lab datasets\n",
    "The following cell will download the dataset used by this lab. Click into the following cell and use `Shift + Enter` to execute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content files will be saved to ../datasets\n",
      "wget -O ../datasets/UsedCars_Clean.csv https://databricksdemostore.blob.core.windows.net/data/aml-labs/UsedCars_Clean.csv\n",
      "wget -O ../datasets/UsedCars_Affordability.csv https://databricksdemostore.blob.core.windows.net/data/aml-labs/UsedCars_Affordability.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['UsedCars_Clean.csv', 'UsedCars_Affordability.csv']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a temporary folder to store locally relevant content for this notebook\n",
    "datasetsFolderName = '../datasets'\n",
    "os.makedirs(datasetsFolderName, exist_ok=True)\n",
    "print('Content files will be saved to {0}'.format(datasetsFolderName))\n",
    "\n",
    "filesToDownload = ['UsedCars_Clean.csv', 'UsedCars_Affordability.csv']\n",
    "\n",
    "for fileToDownload in filesToDownload:\n",
    "  downloadCommand = 'wget -O ''{0}/{1}'' ''https://databricksdemostore.blob.core.windows.net/data/aml-labs/{1}'''.format(datasetsFolderName, fileToDownload)\n",
    "  print(downloadCommand)\n",
    "  os.system(downloadCommand)\n",
    "  \n",
    "#List all downloaded files\n",
    "os.listdir(datasetsFolderName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell loads the sampled dataset. Use `Shift + Enter` to execute the cell. Take a moment to look at the data loaded into the Pandas Dataframe - it contains data about used cars such as the price (in dollars), age (in years), KM (kilometers driven) and other attributes like weather it is automatic transimission, the number of doors, and the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Price  Age     KM FuelType   HP  MetColor  Automatic    CC  Doors  \\\n",
      "0     13500   23  46986   Diesel   90         1          0  2000      3   \n",
      "1     13750   23  72937   Diesel   90         1          0  2000      3   \n",
      "2     13950   24  41711   Diesel   90         1          0  2000      3   \n",
      "3     14950   26  48000   Diesel   90         0          0  2000      3   \n",
      "4     13750   30  38500   Diesel   90         0          0  2000      3   \n",
      "5     12950   32  61000   Diesel   90         0          0  2000      3   \n",
      "6     16900   27  94612   Diesel   90         1          0  2000      3   \n",
      "7     18600   30  75889   Diesel   90         1          0  2000      3   \n",
      "8     21500   27  19700   Petrol  192         0          0  1800      3   \n",
      "9     12950   23  71138   Diesel   69         0          0  1900      3   \n",
      "10    20950   25  31461   Petrol  192         0          0  1800      3   \n",
      "11    19950   22  43610   Petrol  192         0          0  1800      3   \n",
      "12    19600   25  32189   Petrol  192         0          0  1800      3   \n",
      "13    21500   31  23000   Petrol  192         1          0  1800      3   \n",
      "14    22500   32  34131   Petrol  192         1          0  1800      3   \n",
      "15    22000   28  18739   Petrol  192         0          0  1800      3   \n",
      "16    22750   30  34000   Petrol  192         1          0  1800      3   \n",
      "17    17950   24  21716   Petrol  110         1          0  1600      3   \n",
      "18    16750   24  25563   Petrol  110         0          0  1600      3   \n",
      "19    16950   30  64359   Petrol  110         1          0  1600      3   \n",
      "20    15950   30  67660   Petrol  110         1          0  1600      3   \n",
      "21    16950   29  43905   Petrol  110         0          1  1600      3   \n",
      "22    15950   28  56349   Petrol  110         1          0  1600      3   \n",
      "23    16950   28  32220   Petrol  110         1          0  1600      3   \n",
      "24    16250   29  25813   Petrol  110         1          0  1600      3   \n",
      "25    15950   25  28450   Petrol  110         1          0  1600      3   \n",
      "26    17495   27  34545   Petrol  110         1          0  1600      3   \n",
      "27    15750   29  41415   Petrol  110         1          0  1600      3   \n",
      "28    16950   28  44142   Petrol  110         0          0  1600      3   \n",
      "29    17950   30  11090   Petrol  110         1          0  1600      3   \n",
      "...     ...  ...    ...      ...  ...       ...        ...   ...    ...   \n",
      "1406   8950   70  44850   Petrol  110         1          0  1600      3   \n",
      "1407   8250   69  44826   Petrol  110         0          0  1600      5   \n",
      "1408   9250   80  44444   Petrol  110         1          0  1600      3   \n",
      "1409   7900   75  43720   Petrol  110         1          0  1600      5   \n",
      "1410   8500   78  43622   Petrol   86         1          0  1300      4   \n",
      "1411   7950   76  43532   Petrol  110         0          0  1600      5   \n",
      "1412   9950   69  42800   Petrol  110         1          0  1600      3   \n",
      "1413   8750   74  42317   Petrol  107         1          1  1600      5   \n",
      "1414   7500   80  42186   Petrol  110         1          0  1600      3   \n",
      "1415   6950   72  42000   Petrol  110         1          0  1600      3   \n",
      "1416   8950   79  40093   Petrol  110         0          0  1600      5   \n",
      "1417   8750   79  39800   Petrol  107         0          1  1600      3   \n",
      "1418   7750   73  39168   Petrol   86         0          0  1300      3   \n",
      "1419   8450   75  38945   Petrol  110         1          0  1600      3   \n",
      "1420   8150   76  36537   Petrol  110         0          1  1600      4   \n",
      "1421   8500   78  36000   Petrol   86         0          1  1300      3   \n",
      "1422   7600   78  36000   Petrol  110         1          0  1600      3   \n",
      "1423   7950   80  35821   Petrol   86         0          1  1300      3   \n",
      "1424   7750   73  34717   Petrol   86         0          0  1300      3   \n",
      "1425   7950   80  34000   Petrol   86         1          0  1300      4   \n",
      "1426   9950   78  30964   Petrol  110         0          1  1600      3   \n",
      "1427   8950   71  29000   Petrol   86         1          1  1300      3   \n",
      "1428   8450   72  26000   Petrol   86         0          0  1300      3   \n",
      "1429   8950   78  24000   Petrol   86         1          1  1300      5   \n",
      "1430   8450   80  23000   Petrol   86         0          0  1300      3   \n",
      "1431   7500   69  20544   Petrol   86         1          0  1300      3   \n",
      "1432  10845   72  19000   Petrol   86         0          0  1300      3   \n",
      "1433   8500   71  17016   Petrol   86         0          0  1300      3   \n",
      "1434   7250   70  16916   Petrol   86         1          0  1300      3   \n",
      "1435   6950   76      1   Petrol  110         0          0  1600      5   \n",
      "\n",
      "      Weight  \n",
      "0       1165  \n",
      "1       1165  \n",
      "2       1165  \n",
      "3       1165  \n",
      "4       1170  \n",
      "5       1170  \n",
      "6       1245  \n",
      "7       1245  \n",
      "8       1185  \n",
      "9       1105  \n",
      "10      1185  \n",
      "11      1185  \n",
      "12      1185  \n",
      "13      1185  \n",
      "14      1185  \n",
      "15      1185  \n",
      "16      1185  \n",
      "17      1105  \n",
      "18      1065  \n",
      "19      1105  \n",
      "20      1105  \n",
      "21      1170  \n",
      "22      1120  \n",
      "23      1120  \n",
      "24      1120  \n",
      "25      1120  \n",
      "26      1120  \n",
      "27      1120  \n",
      "28      1120  \n",
      "29      1120  \n",
      "...      ...  \n",
      "1406    1050  \n",
      "1407    1075  \n",
      "1408    1050  \n",
      "1409    1070  \n",
      "1410    1000  \n",
      "1411    1070  \n",
      "1412    1050  \n",
      "1413    1100  \n",
      "1414    1050  \n",
      "1415    1050  \n",
      "1416    1114  \n",
      "1417    1080  \n",
      "1418    1015  \n",
      "1419    1050  \n",
      "1420    1075  \n",
      "1421    1045  \n",
      "1422    1050  \n",
      "1423    1015  \n",
      "1424    1015  \n",
      "1425    1000  \n",
      "1426    1080  \n",
      "1427    1045  \n",
      "1428    1015  \n",
      "1429    1065  \n",
      "1430    1015  \n",
      "1431    1025  \n",
      "1432    1015  \n",
      "1433    1015  \n",
      "1434    1015  \n",
      "1435    1114  \n",
      "\n",
      "[1436 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pathToCsvFile = os.path.join(datasetsFolderName, 'UsedCars_Clean.csv')\n",
    "df = pd.read_csv(pathToCsvFile, delimiter=',')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to try and build a model that can answer the question \"Can I afford a car that is X months old and has Y kilometers on it, given I have $12,000 to spend?\". We will engineer the label for affordable. Execute the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age     KM  Affordable\n",
      "0      23  46986           0\n",
      "1      23  72937           0\n",
      "2      24  41711           0\n",
      "3      26  48000           0\n",
      "4      30  38500           0\n",
      "5      32  61000           0\n",
      "6      27  94612           0\n",
      "7      30  75889           0\n",
      "8      27  19700           0\n",
      "9      23  71138           0\n",
      "10     25  31461           0\n",
      "11     22  43610           0\n",
      "12     25  32189           0\n",
      "13     31  23000           0\n",
      "14     32  34131           0\n",
      "15     28  18739           0\n",
      "16     30  34000           0\n",
      "17     24  21716           0\n",
      "18     24  25563           0\n",
      "19     30  64359           0\n",
      "20     30  67660           0\n",
      "21     29  43905           0\n",
      "22     28  56349           0\n",
      "23     28  32220           0\n",
      "24     29  25813           0\n",
      "25     25  28450           0\n",
      "26     27  34545           0\n",
      "27     29  41415           0\n",
      "28     28  44142           0\n",
      "29     30  11090           0\n",
      "...   ...    ...         ...\n",
      "1406   70  44850           1\n",
      "1407   69  44826           1\n",
      "1408   80  44444           1\n",
      "1409   75  43720           1\n",
      "1410   78  43622           1\n",
      "1411   76  43532           1\n",
      "1412   69  42800           1\n",
      "1413   74  42317           1\n",
      "1414   80  42186           1\n",
      "1415   72  42000           1\n",
      "1416   79  40093           1\n",
      "1417   79  39800           1\n",
      "1418   73  39168           1\n",
      "1419   75  38945           1\n",
      "1420   76  36537           1\n",
      "1421   78  36000           1\n",
      "1422   78  36000           1\n",
      "1423   80  35821           1\n",
      "1424   73  34717           1\n",
      "1425   80  34000           1\n",
      "1426   78  30964           1\n",
      "1427   71  29000           1\n",
      "1428   72  26000           1\n",
      "1429   78  24000           1\n",
      "1430   80  23000           1\n",
      "1431   69  20544           1\n",
      "1432   72  19000           1\n",
      "1433   71  17016           1\n",
      "1434   70  16916           1\n",
      "1435   76      1           1\n",
      "\n",
      "[1436 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Add the affordable feature\n",
    "\n",
    "df['Affordable'] = np.where(df['Price']<12000, 1, 0)\n",
    "df_affordability = df[[\"Age\",\"KM\", \"Affordable\"]]\n",
    "print(df_affordability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to train a Logistic Regression model in Azure Databricks. This type of model requires us to standardize the scale of our training features Age and KM, so we use the `StandardScaler` from Scikit-Learn to transform these features so that they have values centered with a mean around 0 (mostly between -2.96 and 1.29). Select Step 3 and execute the code. Observe the difference in min and max values between the un-scaled and scaled Dataframes. When we use Sci-Kit Learn, these models are trained on the driver node. Execute the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0          1\n",
      "count  1436.00    1436.00\n",
      "mean     55.95   68533.26\n",
      "std      18.60   37506.45\n",
      "min       1.00       1.00\n",
      "25%      44.00   43000.00\n",
      "50%      61.00   63389.50\n",
      "75%      70.00   87020.75\n",
      "max      80.00  243000.00\n",
      "             0        1\n",
      "count  1436.00  1436.00\n",
      "mean     -0.00     0.00\n",
      "std       1.00     1.00\n",
      "min      -2.96    -1.83\n",
      "25%      -0.64    -0.68\n",
      "50%       0.27    -0.14\n",
      "75%       0.76     0.49\n",
      "max       1.29     4.65\n"
     ]
    }
   ],
   "source": [
    "# Scale the numeric feature values\n",
    "\n",
    "X = df_affordability[[\"Age\", \"KM\"]].values\n",
    "y = df_affordability[[\"Affordable\"]].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.astype(float))\n",
    "\n",
    "print(pd.DataFrame(X).describe().round(2))\n",
    "print(pd.DataFrame(X_scaled).describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model by fitting a LogisticRegression against the scaled input features (X_scaled) and the labels (y). Execute the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a Logistic Regression\n",
    "\n",
    "from sklearn import linear_model\n",
    "# Create a linear model for Logistic Regression\n",
    "clf = linear_model.LogisticRegression(C=1)\n",
    "\n",
    "# Flatten labels\n",
    "y = np.ravel(y)\n",
    "\n",
    "# we create an instance of Classifier and fit the data.\n",
    "clf.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try prediction - if you set the age to 60 months and km to 40,000, does the model predict you can afford the car? Execute the cell and find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I afford a car that is 60 month(s) old with 40000 KM's on it?\n",
      "Yes (1)\n"
     ]
    }
   ],
   "source": [
    "# Test the trained model's prediction\n",
    "\n",
    "age = 60\n",
    "km = 40000\n",
    "\n",
    "scaled_input = scaler.transform([[age, km]])\n",
    "prediction = clf.predict(scaled_input)\n",
    "\n",
    "print(\"Can I afford a car that is {} month(s) old with {} KM's on it?\".format(age,km))\n",
    "print(\"Yes (1)\" if prediction[0] == 1 else \"No (0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's get a sense for how accurate the model is. Execute the following cell. What was your model's accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n",
      "Model Accuracy: 0.926\n"
     ]
    }
   ],
   "source": [
    "# Measure the model's performance\n",
    "\n",
    "scaled_inputs = scaler.transform(X.astype(float))\n",
    "predictions = clf.predict(scaled_inputs)\n",
    "print(predictions)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "score = accuracy_score(y, predictions)\n",
    "print(\"Model Accuracy: {}\".format(score.round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that can affect the model's performance is how much data of all the labeled training data available is used to train the model. In the next cell, you define a method that uses train_test_split from Scikit-Learn that will enable you to split the data using different percentages. Execute the cell to register this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a method to experiment with different training subset sizes\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "full_X = df_affordability[[\"Age\", \"KM\"]]\n",
    "full_Y = df_affordability[[\"Affordable\"]]\n",
    "\n",
    "def train_eval_model(full_X, full_Y,training_set_percentage):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, train_size=training_set_percentage, random_state=42)\n",
    "    \n",
    "    # Flatten labels\n",
    "    train_Y = np.ravel(train_Y)\n",
    "    test_Y = np.ravel(test_Y)\n",
    "    \n",
    "    # Convert to float\n",
    "    train_X = train_X.astype(float)\n",
    "    test_X = test_X.astype(float)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(train_X)\n",
    "    clf = linear_model.LogisticRegression(C=1)\n",
    "    clf.fit(X_scaled, train_Y)\n",
    "\n",
    "    scaled_inputs = scaler.transform(test_X)\n",
    "    predictions = clf.predict(scaled_inputs)\n",
    "    score = accuracy_score(test_Y, predictions)\n",
    "\n",
    "    return (clf, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Azure Machine Learning to log performance metrics\n",
    "In the steps that follow, you will train multiple models using different sizes of training data and observe the impact on performance (accuracy). Each time you create a new model, you are executing a Run in the terminology of Azure Machine Learning service. In this case, you will create one Experiment and execute multiple Runs within it, each with different training percentages (and resultant varying accuracies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the following cell to quickly verify you have the Azure Machine Learning SDK installed on your cluster. If you get a version number back without error, you are ready to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK Version: 1.0.2\n"
     ]
    }
   ],
   "source": [
    "# Verify AML SDK Installed\n",
    "\n",
    "import azureml.core\n",
    "print(\"SDK Version:\", azureml.core.VERSION)\n",
    "\n",
    "# import the Workspace class \n",
    "from azureml.core import Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All Azure Machine Learning entities are organized within a Workspace. You can create an AML Workspace in the Azure Portal, but as the code in the following cell shows, you can also create a Workspace directly from code. Set the values for `subscription_id`, `resource_group`, `workspace_name` and `workspace_region` as directed by the comments. Execute Step 9. You will be prompted to log in to your Azure Subscription by the command output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a workspace\n",
    "\n",
    "#Provide the Subscription ID of your existing Azure subscription\n",
    "subscription_id = \"<your subscription>\"\n",
    "\n",
    "#Provide values for the Resource Group and Workspace that will be created\n",
    "resource_group = \"<your resource group>\"\n",
    "workspace_name = \"<your workspace name>\"\n",
    "workspace_region = \"<your region>\"\n",
    "\n",
    "ws = Workspace.create(\n",
    "    name = workspace_name,\n",
    "    subscription_id = subscription_id,\n",
    "    resource_group = resource_group, \n",
    "    location = workspace_region,\n",
    "    exist_ok = True)\n",
    "\n",
    "print(\"Workspace Provisioning complete.\")\n",
    "ws.get_details()\n",
    "ws.write_config('../')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin capturing metrics, you must first create an Experiment and then call `start_logging()` on that Experiment. The return value of this call is a Run. This root run can have other child runs. When you are finished with an experiment run, use `complete()` to close out the root run. Execute the following cell to train four different models using differing amounts of training data and log the results to Azure Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/aml/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 0.25 percent of data, model accuracy reached 0.9192.\n",
      "With 0.50 percent of data, model accuracy reached 0.9109.\n",
      "With 0.75 percent of data, model accuracy reached 0.9081.\n",
      "With 0.90 percent of data, model accuracy reached 0.9306.\n"
     ]
    }
   ],
   "source": [
    "# Create an experiment and log metrics for multiple training runs\n",
    "\n",
    "from azureml.core.run import Run\n",
    "from azureml.core.experiment import Experiment\n",
    "\n",
    "# start a training run by defining an experiment\n",
    "myexperiment = Experiment(ws, \"usedcars_training_local\")\n",
    "root_run = myexperiment.start_logging()\n",
    "\n",
    "training_set_percentage = 0.25\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage)\n",
    "print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "training_set_percentage = 0.5\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage)\n",
    "print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "training_set_percentage = 0.75\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage)\n",
    "print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "training_set_percentage = 0.9\n",
    "run = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage)\n",
    "print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"Accuracy\", score)\n",
    "run.complete()\n",
    "\n",
    "# Close out the experiment\n",
    "root_run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have captured history for various runs, you can review the runs. You could use the Azure Portal for this - go to the Azure Portal, find your Azure Machine Learning Workspace, select Experiments and select the UsedCars_Experiment. However, in this case we will use the AML SDK to query for the runs. Execute the following cell to view the runs and their status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Run(Experiment: usedcars_training_local,\n",
      "Id: d119886e-e72c-4fe2-b773-afb01a808810,\n",
      "Type: None,\n",
      "Status: Completed), Run(Experiment: usedcars_training_local,\n",
      "Id: 6f945f31-b790-46cb-97ac-e9d9094019fb,\n",
      "Type: None,\n",
      "Status: Completed), Run(Experiment: usedcars_training_local,\n",
      "Id: d06cb46d-f210-44e5-8a6e-a3bdc2178166,\n",
      "Type: None,\n",
      "Status: Completed), Run(Experiment: usedcars_training_local,\n",
      "Id: d3e6f313-3cd0-4eb1-992e-c52d726e18fa,\n",
      "Type: None,\n",
      "Status: Completed)]\n"
     ]
    }
   ],
   "source": [
    "# Review captured runs\n",
    "# Go to the Azure Portal, find your Azure Machine Learning Workspace, select Experiments and select the UsedCars_Experiment\n",
    "\n",
    "# You can also query the run history using the SDK.\n",
    "# The following command lists all of the runs for the experiment\n",
    "runs = [r for r in root_run.get_children()]\n",
    "print(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train remotely using Azure ML Compute\n",
    "\n",
    "Up until now, all of your training was executed locally on the same machine running Jupyter. Now you will execute the same logic targeting a remote Azure ML Compute, which you will provision from code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /Users/jarekk/repos/jakazmie/AMLsWorkshop/01-Model-Training/aml_config/config.json\n",
      "jkamlslabs\n",
      "jkamlslabs\n",
      "eastus\n",
      "952a710c-8d9c-40c1-9fec-f752138cc0b3\n"
     ]
    }
   ],
   "source": [
    "# Connect to workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing compute target, using this compute target instead of creating:  cpu-bai-cluster\n"
     ]
    }
   ],
   "source": [
    "# Create an Azure ML Compute cluster\n",
    "\n",
    "# Create Azure ML cluster\n",
    "from azureml.core.compute import AmlCompute\n",
    "from azureml.core.compute import ComputeTarget\n",
    "import os\n",
    "\n",
    "# choose a name for your cluster\n",
    "cluster_name = \"cpu-bai-cluster\"\n",
    "cluster_min_nodes = 1\n",
    "cluster_max_nodes = 3\n",
    "vm_size = \"STANDARD_DS11_V2\"\n",
    "\n",
    "if cluster_name in ws.compute_targets:\n",
    "    compute_target = ws.compute_targets[cluster_name]\n",
    "    if compute_target and type(compute_target) is AmlCompute:\n",
    "        print('Found existing compute target, using this compute target instead of creating:  ' + cluster_name)\n",
    "    else:\n",
    "        print(\"Error: A compute target with name \",cluster_name,\" was found, but it is not of type AmlCompute.\")\n",
    "else:\n",
    "    print('Creating a new compute target...')\n",
    "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size, \n",
    "                                                                min_nodes = cluster_min_nodes, \n",
    "                                                                max_nodes = cluster_max_nodes)\n",
    "\n",
    "    # create the cluster\n",
    "    compute_target = ComputeTarget.create(ws, cluster_name, provisioning_config)\n",
    "    \n",
    "    # can poll for a minimum number of nodes and for a specific timeout. \n",
    "    # if no min node count is provided it will use the scale settings for the cluster\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n",
    "    \n",
    "     # For a more detailed view of current BatchAI cluster status, use the 'status' property    \n",
    "    print(compute_target.status.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your cluster ready, you need to upload the training data to the default DataStore for your AML Workspace (which uses Azure Storage). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AzureBlob jkamlslastoragetanccklq azureml-blobstore-54a9725e-afa3-4ac0-99a4-b171b84e2213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_3b90d7b3da4445f39b6f6497f16f9206"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload the dataset to the DataStore\n",
    "\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.datastore_type, ds.account_name, ds.container_name)\n",
    "ds.upload(src_dir='../datasets', target_path='used_cars', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you will need to create a training script that is similar to the code you have executed locally to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './script'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./script/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/train.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import linear_model \n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from azureml.core import Run\n",
    "\n",
    "# let user feed in 2 parameters, the location of the data files (from datastore), and the training set percentage to use\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data-folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "parser.add_argument('--training-set-percentage', type=float, dest='training_set_percentage', default=0.25, help='percentage of dataset to use for training')\n",
    "args = parser.parse_args()\n",
    "\n",
    "data_folder = os.path.join(args.data_folder, 'used_cars')\n",
    "print('Data folder:', data_folder)\n",
    "data_csv_path = os.path.join(data_folder, 'UsedCars_Clean.csv')\n",
    "print('Path to CSV file dataset:' + data_csv_path)\n",
    "\n",
    "# Load the data\n",
    "#df = pd.read_csv('UsedCars_Clean.csv', delimiter=',')\n",
    "df = pd.read_csv(data_csv_path)\n",
    "df['Affordable'] = np.where(df['Price']<12000, 1, 0)\n",
    "df_affordability = df[[\"Age\",\"KM\", \"Affordable\"]]\n",
    "\n",
    "\n",
    "# Now experiment with different training subsets\n",
    "from sklearn.model_selection import train_test_split\n",
    "full_X = df_affordability[[\"Age\", \"KM\"]]\n",
    "full_Y = df_affordability[[\"Affordable\"]]\n",
    "\n",
    "def train_eval_model(full_X, full_Y,training_set_percentage):\n",
    "    train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, train_size=training_set_percentage, random_state=42)\n",
    "    \n",
    "    # Flatten labels\n",
    "    train_Y = np.ravel(train_Y)\n",
    "    test_Y = np.ravel(test_Y)\n",
    "    \n",
    "    # Convert to float\n",
    "    train_X = train_X.astype(float)\n",
    "    test_X = test_X.astype(float)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(train_X)\n",
    "    clf = linear_model.LogisticRegression(C=1)\n",
    "    clf.fit(X_scaled, train_Y)\n",
    "\n",
    "    scaled_inputs = scaler.transform(test_X)\n",
    "    predictions = clf.predict(scaled_inputs)\n",
    "    score = accuracy_score(test_Y, predictions)\n",
    "\n",
    "    return (clf, score)\n",
    "\n",
    "# Acquire the current run\n",
    "run = Run.get_context()\n",
    "\n",
    "\n",
    "training_set_percentage = args.training_set_percentage\n",
    "model, score = train_eval_model(full_X, full_Y, training_set_percentage)\n",
    "print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n",
    "run.log(\"Training_Set_Percentage\", training_set_percentage)\n",
    "run.log(\"Accuracy\", score)\n",
    "\n",
    "\n",
    "# note file saved in the outputs folder is automatically uploaded into experiment record\n",
    "joblib.dump(value=model, filename='outputs/model.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an estimator that descrives the configuration of the job that will execute your model training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14 - Create estimator\n",
    "#############################\n",
    "from azureml.train.estimator import Estimator\n",
    "\n",
    "script_params = {\n",
    "    '--data-folder': ds.as_mount(),\n",
    "    '--training-set-percentage': 0.3\n",
    "}\n",
    "\n",
    "est_config = Estimator(source_directory=script_folder,\n",
    "                       script_params=script_params,\n",
    "                       compute_target=compute_target,\n",
    "                       entry_script='train.py',\n",
    "                       conda_packages=['scikit-learn', 'pandas'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit the job using the submit() method of the Experiment object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>usedcars_training_amlcompute</td><td>usedcars_training_amlcompute_1544415675536</td><td>azureml.scriptrun</td><td>Queued</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/952a710c-8d9c-40c1-9fec-f752138cc0b3/resourceGroups/jkamlslabs/providers/Microsoft.MachineLearningServices/workspaces/jkamlslabs/experiments/usedcars_training_amlcompute/runs/usedcars_training_amlcompute_1544415675536\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: usedcars_training_amlcompute,\n",
       "Id: usedcars_training_amlcompute_1544415675536,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Queued)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 15 - Execute the estimator job\n",
    "#####################################\n",
    "\n",
    "# Create new experiment\n",
    "from azureml.core import Experiment\n",
    "experiment_name = \"usedcars_training_amlcompute\"\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "\n",
    "run = exp.submit(config=est_config)\n",
    "run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can monitor the job through Azure Portal or using AML Jupyter Widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ac5d3667ae45f8a757439b02a0973f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': True, 'log_level': 'INFO', 'sâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from azureml.widgets import RunDetails\n",
    "RunDetails(run).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: usedcars_training_amlcompute_1544415675536\n",
      "\n",
      "Streaming azureml-logs/60_control_log.txt\n",
      "=========================================\n",
      "\n",
      "Streaming log file azureml-logs/60_control_log.txt\n",
      "Streaming log file azureml-logs/80_driver_log.txt\n",
      "\n",
      "Streaming azureml-logs/80_driver_log.txt\n",
      "========================================\n",
      "\n",
      "Data folder: /mnt/batch/tasks/shared/LS_root/jobs/jkamlslabs/azureml/usedcars_training_amlcompute_1544415675536/mounts/workspaceblobstore/used_cars\n",
      "Path to CSV file dataset:/mnt/batch/tasks/shared/LS_root/jobs/jkamlslabs/azureml/usedcars_training_amlcompute_1544415675536/mounts/workspaceblobstore/used_cars/UsedCars_Clean.csv\n",
      "/azureml-envs/azureml_c072de61be6a89e821f89860d9cc84d4/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/azureml-envs/azureml_c072de61be6a89e821f89860d9cc84d4/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "With 0.30 percent of data, model accuracy reached 0.9175.\n",
      "\n",
      "\n",
      "The experiment completed successfully. Finalizing run...\n",
      "Logging experiment finalizing status in history service\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.20168709754943848 seconds\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: usedcars_training_amlcompute_1544415675536\n",
      "\n",
      "{'Training_Set_Percentage': 0.3, 'Accuracy': 0.9174950298210736}\n"
     ]
    }
   ],
   "source": [
    "# Poll for job status\n",
    "run.wait_for_completion(show_output=True)  # value of True will display a verbose, streaming log\n",
    "\n",
    "# Examine the recorded metrics from the run\n",
    "print(run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "name": "01 model training",
  "notebookId": 863281121960369
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
