{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Lab 1 - Training a Machine Learning Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "In this lab you will setup the Azure Machine Learning service and use it for tracking training of a `scikit-learn` model."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Download the datasets"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The following cell will download the dataset used by this lab. Click into the following cell and use `Shift + Enter` to execute it"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\n\n# Create a temporary folder to store locally relevant content for this notebook\ndatasetsFolderName = '../datasets'\nos.makedirs(datasetsFolderName, exist_ok=True)\nprint('Content files will be saved to {0}'.format(datasetsFolderName))\n\nfilesToDownload = ['UsedCars_Clean.csv', 'UsedCars_Affordability.csv']\n\nfor fileToDownload in filesToDownload:\n  downloadCommand = 'wget -O ''{0}/{1}'' ''https://databricksdemostore.blob.core.windows.net/data/aml-labs/{1}'''.format(datasetsFolderName, fileToDownload)\n  print(downloadCommand)\n  os.system(downloadCommand)\n  \n#List all downloaded files\nos.listdir(datasetsFolderName)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Train a simple model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "The following cell loads the sampled dataset. Use `Shift + Enter` to execute the cell. Take a moment to look at the data loaded into the Pandas Dataframe - it contains data about used cars such as the price (in dollars), age (in years), KM (kilometers driven) and other attributes like weather it is automatic transimission, the number of doors, and the weight."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 1 - load the data\n########################\nimport numpy as np\nimport pandas as pd\nimport os\n\npathToCsvFile = os.path.join(datasetsFolderName, 'UsedCars_Clean.csv')\ndf = pd.read_csv(pathToCsvFile, delimiter=',')\nprint(df)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We are going to try and build a model that can answer the question \"Can I afford a car that is X months old and has Y kilometers on it, given I have $12,000 to spend?\". We will engineer the label for affordable. Execute the following cell."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 2 - add the affordable feature\n######################################\ndf['Affordable'] = np.where(df['Price']<12000, 1, 0)\ndf_affordability = df[[\"Age\",\"KM\", \"Affordable\"]]\nprint(df_affordability)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "We are going to train a Logistic Regression model in Azure Databricks. This type of model requires us to standardize the scale of our training features Age and KM, so we use the `StandardScaler` from Scikit-Learn to transform these features so that they have values centered with a mean around 0 (mostly between -2.96 and 1.29). Select Step 3 and execute the code. Observe the difference in min and max values between the un-scaled and scaled Dataframes. When we use Sci-Kit Learn, these models are trained on the driver node. Execute the following cell."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 3 - Scale the numeric feature values\n###########################################\nX = df_affordability[[\"Age\", \"KM\"]].values\ny = df_affordability[[\"Affordable\"]].values\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X.astype(float))\n\nprint(pd.DataFrame(X).describe().round(2))\nprint(pd.DataFrame(X_scaled).describe().round(2))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Train the model by fitting a LogisticRegression against the scaled input features (X_scaled) and the labels (y). Execute the following cell."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 4 - Fit a Logistic Regression\n####################################\nfrom sklearn import linear_model\n# Create a linear model for Logistic Regression\nclf = linear_model.LogisticRegression(C=1)\n\n# Flatten labels\ny = np.ravel(y)\n\n# we create an instance of Classifier and fit the data.\nclf.fit(X_scaled, y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Try prediction - if you set the age to 60 months and km to 40,000, does the model predict you can afford the car? Execute the cell and find out."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 5 - Test the trained model's prediction\n##############################################\nage = 60\nkm = 40000\n\nscaled_input = scaler.transform([[age, km]])\nprediction = clf.predict(scaled_input)\n\nprint(\"Can I afford a car that is {} month(s) old with {} KM's on it?\".format(age,km))\nprint(\"Yes (1)\" if prediction[0] == 1 else \"No (0)\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, let's get a sense for how accurate the model is. Execute the following cell. What was your model's accuracy?"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 6 - Measure the model's performance\n##########################################\nscaled_inputs = scaler.transform(X.astype(float))\npredictions = clf.predict(scaled_inputs)\nprint(predictions)\n\nfrom sklearn.metrics import accuracy_score\nscore = accuracy_score(y, predictions)\nprint(\"Model Accuracy: {}\".format(score.round(3)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "One thing that can affect the model's performance is how much data of all the labeled training data available is used to train the model. In the next cell, you define a method that uses train_test_split from Scikit-Learn that will enable you to split the data using different percentages. Execute the cell to register this function."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 7 - Define a method to experiment with different training subset sizes\n#############################################################################\nfrom sklearn.model_selection import train_test_split\nfull_X = df_affordability[[\"Age\", \"KM\"]]\nfull_Y = df_affordability[[\"Affordable\"]]\n\ndef train_eval_model(full_X, full_Y,training_set_percentage):\n    train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, train_size=training_set_percentage, random_state=42)\n\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(train_X)\n    clf = linear_model.LogisticRegression(C=1)\n    clf.fit(X_scaled, train_Y)\n\n    scaled_inputs = scaler.transform(test_X)\n    predictions = clf.predict(scaled_inputs)\n    score = accuracy_score(test_Y, predictions)\n\n    return (clf, score)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Use Azure Machine Learning to log performance metrics\nIn the steps that follow, you will train multiple models using different sizes of training data and observe the impact on performance (accuracy). Each time you create a new model, you are executing a Run in the terminology of Azure Machine Learning service. In this case, you will create one Experiment and execute multiple Runs within it, each with different training percentages (and resultant varying accuracies)."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Execute the following cell to quickly verify you have the Azure Machine Learning SDK installed on your cluster. If you get a version number back without error, you are ready to proceed."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 8 - Verify AML SDK Installed\n#####################################################################\nimport azureml.core\nprint(\"SDK Version:\", azureml.core.VERSION)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "All Azure Machine Learning entities are organized within a Workspace. You can create an AML Workspace in the Azure Portal, but as the code in the following cell shows, you can also create a Workspace directly from code. Set the values for `subscription_id`, `resource_group`, `workspace_name` and `workspace_region` as directed by the comments. Execute Step 9. You will be prompted to log in to your Azure Subscription by the command output."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 9 - Create a workspace\n#####################################################################\n\n#Provide the Subscription ID of your existing Azure subscription\nsubscription_id = \"<your subscription>\"\n\n#Provide values for the Resource Group and Workspace that will be created\nresource_group = \"<your resource group>\"\nworkspace_name = \"<your workspace name>\"\nworkspace_region = \"<your region>\"\n\n\nimport azureml.core\n\n# import the Workspace class \nfrom azureml.core import Workspace\n\nws = Workspace.create(\n    name = workspace_name,\n    subscription_id = subscription_id,\n    resource_group = resource_group, \n    location = workspace_region,\n    exist_ok = True)\n\nprint(\"Workspace Provisioning complete.\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To begin capturing metrics, you must first create an Experiment and then call `start_logging()` on that Experiment. The return value of this call is a Run. This root run can have other child runs. When you are finished with an experiment run, use `complete()` to close out the root run. Execute the following cell to train four different models using differing amounts of training data and log the results to Azure Machine Learning."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 10 - Create an experiment and log metrics for multiple training runs\n###########################################################################\nfrom azureml.core.run import Run\nfrom azureml.core.experiment import Experiment\n\n# start a training run by defining an experiment\nmyexperiment = Experiment(ws, \"UsedCars_Experiment\")\nroot_run = myexperiment.start_logging()\n\ntraining_set_percentage = 0.25\nrun = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\nmodel, score = train_eval_model(full_X, full_Y, training_set_percentage)\nprint(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\nrun.log(\"Training_Set_Percentage\", training_set_percentage)\nrun.log(\"Accuracy\", score)\nrun.complete()\n\ntraining_set_percentage = 0.5\nrun = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\nmodel, score = train_eval_model(full_X, full_Y, training_set_percentage)\nprint(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\nrun.log(\"Training_Set_Percentage\", training_set_percentage)\nrun.log(\"Accuracy\", score)\nrun.complete()\n\ntraining_set_percentage = 0.75\nrun = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\nmodel, score = train_eval_model(full_X, full_Y, training_set_percentage)\nprint(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\nrun.log(\"Training_Set_Percentage\", training_set_percentage)\nrun.log(\"Accuracy\", score)\nrun.complete()\n\ntraining_set_percentage = 0.9\nrun = root_run.child_run(\"Training_Set_Percentage-%0.5F\" % training_set_percentage)\nmodel, score = train_eval_model(full_X, full_Y, training_set_percentage)\nprint(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\nrun.log(\"Training_Set_Percentage\", training_set_percentage)\nrun.log(\"Accuracy\", score)\nrun.complete()\n\n# Close out the experiment\nroot_run.complete()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that you have captured history for various runs, you can review the runs. You could use the Azure Portal for this - go to the Azure Portal, find your Azure Machine Learning Workspace, select Experiments and select the UsedCars_Experiment. However, in this case we will use the AML SDK to query for the runs. Execute the following cell to view the runs and their status."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Step 11 - Review captured runs\n################################\n# Go to the Azure Portal, find your Azure Machine Learning Workspace, select Experiments and select the UsedCars_Experiment\n\n# You can also query the run history using the SDK.\n# The following command lists all of the runs for the experiment\nruns = [r for r in root_run.get_children()]\nprint(runs)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "name": "01 model training",
    "notebookId": 863281121960369
  },
  "nbformat": 4,
  "nbformat_minor": 1
}